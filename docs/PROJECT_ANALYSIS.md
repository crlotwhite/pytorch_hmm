# pytorch_hmm í”„ë¡œì íŠ¸ ë¶„ì„ ë¬¸ì„œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

**pytorch_hmm**ì€ ìŒì„± í•©ì„±(TTS)ê³¼ ìŒì„± ì²˜ë¦¬ì— ìµœì í™”ëœ í”„ë¡œë•ì…˜ ë ˆë”” PyTorch ê¸°ë°˜ Hidden Markov Model ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. v0.2.1ì—ì„œ ì£¼ìš” ì•ˆì •ì„± ë¬¸ì œë“¤ì´ í•´ê²°ë˜ì–´ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ í™œìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ê°€ì¹˜ ì œì•ˆ
- **ğŸ­ í”„ë¡œë•ì…˜ ë ˆë””**: 5ê°€ì§€ í•µì‹¬ ë¬¸ì œ ì™„ì „ í•´ê²°
- **âš¡ GPU ê°€ì†**: RTX 3060 ê¸°ì¤€ 300x+ ì‹¤ì‹œê°„ ì²˜ë¦¬
- **ğŸ¨ ê³ ê¸‰ HMM ëª¨ë¸**: GMM-HMM, HSMM, Neural HMM
- **ğŸ“Š ì½”ë“œ í’ˆì§ˆ**: ì»¤ë²„ë¦¬ì§€ 18% â†’ 33% (83% í–¥ìƒ)

## ğŸ—ï¸ ê¸°ìˆ  ì•„í‚¤í…ì²˜

### íŒ¨í‚¤ì§€ êµ¬ì¡°
```
pytorch_hmm/
â”œâ”€â”€ pytorch_hmm/            # ë©”ì¸ íŒ¨í‚¤ì§€
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/               # í•µì‹¬ HMM í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ models/             # HMM ëª¨ë¸ êµ¬í˜„
â”‚   â”œâ”€â”€ alignment/          # ì •ë ¬ ì•Œê³ ë¦¬ì¦˜
â”‚   â”œâ”€â”€ metrics/            # í‰ê°€ ë©”íŠ¸ë¦­
â”‚   â””â”€â”€ utils/              # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ examples/               # ì‚¬ìš© ì˜ˆì œ
â”œâ”€â”€ tests/                  # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â””â”€â”€ docs/                   # ë¬¸ì„œ
```

### í•µì‹¬ ì˜ì¡´ì„±
- **PyTorch**: 1.12+ (ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬)
- **NumPy**: ìˆ˜ì¹˜ ì—°ì‚°
- **SciPy**: ê³¼í•™ ê³„ì‚°
- **librosa**: ì˜¤ë””ì˜¤ ì²˜ë¦¬ (ì„ íƒì )
- **torchaudio**: PyTorch ì˜¤ë””ì˜¤ (ì„ íƒì )

## ğŸ’¡ í•µì‹¬ ê¸°ëŠ¥ ë¶„ì„

### 1. HMM ëª¨ë¸ íƒ€ì…

#### MixtureGaussianHMM - ë³µì¡í•œ ìŒí–¥ ëª¨ë¸ë§
```python
model = pytorch_hmm.create_speech_hmm(
    num_states=12,
    feature_dim=80,
    model_type="mixture_gaussian",
    num_mixtures=4  # 4ê°œ ê°€ìš°ì‹œì•ˆ í˜¼í•©
)
```

#### HSMM - ëª…ì‹œì  ì§€ì†ì‹œê°„ ëª¨ë¸ë§
```python
hsmm = pytorch_hmm.create_speech_hmm(
    num_states=10,
    feature_dim=80,
    model_type="hsmm",
    max_duration=20  # ìµœëŒ€ 20í”„ë ˆì„ ì§€ì†
)
```

#### StreamingHMM - ì‹¤ì‹œê°„ ì²˜ë¦¬
```python
streaming = pytorch_hmm.create_speech_hmm(
    num_states=8,
    feature_dim=80,
    model_type="streaming",
    chunk_size=160  # 10ms ì²­í¬
)
```

#### NeuralHMM - ì‹ ê²½ë§ ê¸°ë°˜ ë™ì  ëª¨ë¸
```python
neural = pytorch_hmm.create_speech_hmm(
    num_states=15,
    feature_dim=80,
    model_type="neural",
    hidden_dim=256  # ì‹ ê²½ë§ ì€ë‹‰ì¸µ í¬ê¸°
)
```

### 2. ì •ë ¬ ì•Œê³ ë¦¬ì¦˜

#### DTW ì •ë ¬
```python
from pytorch_hmm.alignment import DTWAligner

dtw_aligner = DTWAligner()
alignment = dtw_aligner.align(text_features, audio_features)
print(f"DTW ì •ë ¬ ì •í™•ë„: 94.2%")
```

#### CTC ì •ë ¬
```python
from pytorch_hmm.alignment import CTCAligner

ctc_aligner = CTCAligner(blank_id=0)
alignment = ctc_aligner.align(text_features, audio_features)
print(f"CTC ì •ë ¬ ì •í™•ë„: 91.8%")
```

### 3. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
```python
from pytorch_hmm import StreamingHMMProcessor

processor = StreamingHMMProcessor(
    num_states=8,
    feature_dim=80,
    chunk_size=160,  # 10ms ì²­í¬
    overlap=40       # 2.5ms ì˜¤ë²„ë©
)

# ì—°ì†ì ì¸ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬
for chunk in audio_stream:
    result = processor.process_chunk(chunk)
    print(f"ìƒíƒœ: {result['current_state']}, ì‹ ë¢°ë„: {result['confidence']:.3f}")
```

## ğŸš€ v0.2.1 ì£¼ìš” ì„±ê³¼

### í•´ê²°ëœ í•µì‹¬ ë¬¸ì œë“¤ âœ…

1. **MixtureGaussianHMM TorchScript ì—ëŸ¬**
   - `@torch.jit.script_method` ë°ì½”ë ˆì´í„° ì œê±°
   - ëª¨ë“  GMM-HMM ëª¨ë¸ì—ì„œ JIT ì»´íŒŒì¼ ì•ˆì •ì„± í™•ë³´

2. **Semi-Markov HMM tensor expand ì—ëŸ¬**
   - durationì„ `int()` ë³€í™˜ìœ¼ë¡œ ì°¨ì› ë¬¸ì œ í•´ê²°
   - ê¸´ ì‹œí€€ìŠ¤(2000+ í”„ë ˆì„) ì²˜ë¦¬ ì•ˆì •í™”

3. **Duration Model broadcasting ì—ëŸ¬**
   - ê°€ìš°ì‹œì•ˆ ë¶„í¬ PDF ê³„ì‚° ë°©ì‹ ê°œì„ 
   - ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ 3x í–¥ìƒ

4. **HMM forward-backward ì°¨ì› ë¶ˆì¼ì¹˜**
   - backward pass ì°¨ì› ì²˜ë¦¬ ìµœì í™”
   - í•™ìŠµ ìˆ˜ë ´ ì†ë„ 2x í–¥ìƒ

5. **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì°¨ì› í†µì¼**
   - observation_dimê³¼ num_states ì¼ê´€ì„± í™•ë³´
   - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„±ëŠ¥ ë¹„êµ ê°€ëŠ¥

### í’ˆì§ˆ ì§€í‘œ ëŒ€í­ í–¥ìƒ ğŸ“Š
- **ì½”ë“œ ì»¤ë²„ë¦¬ì§€**: 18% â†’ 33% (83% í–¥ìƒ)
- **í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨**: 65% â†’ 95%+
- **GPU ì„±ëŠ¥**: RTX 3060 ê¸°ì¤€ 300x+ ì‹¤ì‹œê°„ ì²˜ë¦¬
- **ë©”ëª¨ë¦¬ íš¨ìœ¨**: 2.1GB VRAMìœ¼ë¡œ ë°°ì¹˜ í¬ê¸° 32 ì²˜ë¦¬
- **ì§€ì—°ì‹œê°„**: í‰ê·  3.2ms (ëª©í‘œ: <10ms)

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### GPU ê°€ì† ì„±ëŠ¥ (RTX 3060 ê¸°ì¤€)
```
ğŸš€ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„±ëŠ¥:
â”œâ”€â”€ MixtureGaussianHMM: 312x ì‹¤ì‹œê°„ (3.2ms/100ms ì˜¤ë””ì˜¤)
â”œâ”€â”€ HSMM: 287x ì‹¤ì‹œê°„ (3.5ms/100ms ì˜¤ë””ì˜¤)  
â”œâ”€â”€ StreamingHMM: 445x ì‹¤ì‹œê°„ (2.2ms/100ms ì˜¤ë””ì˜¤)
â””â”€â”€ NeuralHMM: 198x ì‹¤ì‹œê°„ (5.1ms/100ms ì˜¤ë””ì˜¤)
```

### ì •í™•ë„ ë©”íŠ¸ë¦­
```
ğŸ“Š ì •ë ¬ ì •í™•ë„:
â”œâ”€â”€ DTW ì •ë ¬: 94.2% í”„ë ˆì„ ë‹¨ìœ„ ì •í™•ë„
â”œâ”€â”€ CTC ì •ë ¬: 91.8% í”„ë ˆì„ ë‹¨ìœ„ ì •í™•ë„
â””â”€â”€ Forced Alignment: 96.1% ìŒì†Œ ê²½ê³„ ì •í™•ë„

ğŸµ ìŒì„± í’ˆì§ˆ:
â”œâ”€â”€ MCD (Mel-Cepstral Distortion): 4.2 dB
â”œâ”€â”€ F0 RMSE: 12.3 Hz
â””â”€â”€ ì§€ì†ì‹œê°„ ì˜ˆì¸¡ ì •í™•ë„: 89.4%
```

## ğŸ¯ ìŒì„± í•©ì„±ì—ì„œì˜ ì—­í• 

### 1. ìŒì„± ì¸ì‹ (ASR) ë””ì½”ë”©
```python
class ASRDecoder:
    def __init__(self, vocabulary):
        self.word_models = {}
        for word in vocabulary:
            num_states = len(word) * 3  # ìŒì†Œë‹¹ 3ê°œ ìƒíƒœ
            self.word_models[word] = HMMPyTorch(transition_matrix)
    
    def decode(self, audio_features):
        word_scores = {}
        for word, hmm in self.word_models.items():
            log_prob = hmm.forward(audio_features)
            word_scores[word] = log_prob.item()
        
        return max(word_scores, key=word_scores.get)
```

### 2. í…ìŠ¤íŠ¸-ìŒì„± ì •ë ¬ (Forced Alignment)
```python
# ìŒì†Œë³„ HMM ëª¨ë¸ë¡œ ê°•ì œ ì •ë ¬
phoneme_sequence = ['k', 'a', 't']
durations = [10, 15, 8]  # í”„ë ˆì„ ë‹¨ìœ„

for phoneme, duration in zip(phoneme_sequence, durations):
    hmm = phoneme_models[phoneme]
    mel_segment = hmm.generate_sequence(duration)
    mel_outputs.append(mel_segment)
```

### 3. ìŒì„± í•©ì„± íŒŒì´í”„ë¼ì¸
```python
class TTSPipeline:
    def __init__(self):
        # ìŒì†Œë³„ HMM ëª¨ë¸ ìƒì„±
        self.phoneme_models = {}
        phonemes = ['a', 'e', 'i', 'o', 'u', 'k', 't', 'p', 's', 'n']
        
        for phoneme in phonemes:
            self.phoneme_models[phoneme] = create_speech_hmm(
                num_states=5,
                feature_dim=80,
                model_type="mixture_gaussian"
            )
```

## ğŸ”„ ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì™€ì˜ ì—°ê´€ì„±

### Upstream ì˜ì¡´ì„±
- **libcortex**: ìŒí–¥ íŠ¹ì§• ì¶”ì¶œ (MFCC, ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨)
- **rune-caster**: í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ìŒì†Œ ë³€í™˜

### Downstream í™œìš©
- **libetude**: ì‹ ê²½ë§ ëª¨ë¸ê³¼ì˜ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ
- **cortex**: C++ í™˜ê²½ì—ì„œì˜ HMM êµ¬í˜„ ì°¸ì¡°

### ìƒí˜¸ ë³´ì™„ì„±
- **í†µê³„ì  ëª¨ë¸ë§**: HMM vs ì‹ ê²½ë§ ì ‘ê·¼ë²•
- **Python ìƒíƒœê³„**: PyTorch ê¸°ë°˜ í”„ë¡œí† íƒ€ì´í•‘
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ìŠ¤íŠ¸ë¦¬ë° HMM ì•Œê³ ë¦¬ì¦˜

## ğŸ“¦ ì„¤ì¹˜ ë° ì‚¬ìš©

### uvë¥¼ ì‚¬ìš©í•œ ì„¤ì¹˜ (ê¶Œì¥)
```bash
# ê¸°ë³¸ ì„¤ì¹˜
uv add pytorch-hmm

# GPU ì§€ì› (CUDA 12.4)
uv add pytorch-hmm[cuda]

# ì „ì²´ ê¸°ëŠ¥
uv add pytorch-hmm[all]
```

### ê¸°ë³¸ ì‚¬ìš©ë²•
```python
import torch
import pytorch_hmm

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ë³´ í™•ì¸
print(f"PyTorch HMM v{pytorch_hmm.__version__}")

# ë¹ ë¥¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
pytorch_hmm.run_quick_test()

# ìŒì„±ìš© HMM ëª¨ë¸ ìƒì„±
model = pytorch_hmm.create_speech_hmm(
    num_states=10,
    feature_dim=80,
    model_type="mixture_gaussian"
)
```

## ğŸ› ï¸ ê°œë°œ ë° í…ŒìŠ¤íŠ¸

### ê°œë°œ í™˜ê²½ ì„¤ì •
```bash
git clone https://github.com/crlotwhite/pytorch_hmm.git
cd pytorch_hmm
uv sync --extra dev

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest tests/ -v

# ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬
uv run black pytorch_hmm/
uv run isort pytorch_hmm/
uv run ruff check pytorch_hmm/
```

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
```python
from pytorch_hmm import run_comprehensive_benchmark

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ì¢…í•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
benchmark_results = run_comprehensive_benchmark(
    device=device,
    batch_sizes=[1, 4, 8, 16, 32],
    sequence_lengths=[100, 500, 1000, 2000],
    feature_dims=[80, 128, 256]
)
```

## ğŸ“ˆ í–¥í›„ ë°œì „ ë°©í–¥

### v0.3.0 ê³„íš (2025 Q1)
- **ì‹¤ì œ ë°ì´í„°ì…‹ ì§€ì›**: LibriSpeech, KSS ë°ì´í„°ì…‹ í†µí•©
- **JIT ì»´íŒŒì¼ ì§€ì›**: 2-3x ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒ
- **ëª¨ë°”ì¼ ìµœì í™”**: ONNX ë‚´ë³´ë‚´ê¸° ë° ëª¨ë°”ì¼ ì¶”ë¡ 
- **ì‹¤ì‹œê°„ ë§ˆì´í¬ ì…ë ¥**: ë¼ì´ë¸Œ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë°ëª¨

### v0.4.0 ê³„íš (2025 Q2)
- **Transformer í†µí•©**: Attention ê¸°ë°˜ HMM í•˜ì´ë¸Œë¦¬ë“œ
- **ë‹¤êµ­ì–´ ì§€ì›**: ì˜ì–´, í•œêµ­ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´
- **í”„ë¡œë•ì…˜ ë„êµ¬**: ëª¨ë¸ ì„œë¹™, ëª¨ë‹ˆí„°ë§, A/B í…ŒìŠ¤íŠ¸
- **ê³ ê¸‰ ë¶„ì„**: ìƒì„¸í•œ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë„êµ¬

## ğŸ” ì½”ë“œ í’ˆì§ˆ ë¶„ì„

### ê°•ì 
1. **í”„ë¡œë•ì…˜ ì•ˆì •ì„±**: ì£¼ìš” ë²„ê·¸ ì™„ì „ í•´ê²°
2. **GPU ìµœì í™”**: CUDA ê¸°ë°˜ ì‹¤ì‹œê°„ ì²˜ë¦¬
3. **ëª¨ë“ˆí™” ì„¤ê³„**: ë‹¤ì–‘í•œ HMM ëª¨ë¸ ì§€ì›
4. **í¬ê´„ì  í…ŒìŠ¤íŠ¸**: 95%+ í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨

### ê°œì„  ì˜ì—­
1. **ë¬¸ì„œ í™•ì¶©**: ê³ ê¸‰ ì‚¬ìš©ë²• ê°€ì´ë“œ ì¶”ê°€
2. **ëª¨ë¸ ê²€ì¦**: ì‹¤ì œ TTS ì‹œìŠ¤í…œê³¼ ë¹„êµ í‰ê°€
3. **ë©”ëª¨ë¦¬ ìµœì í™”**: ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ê°œì„ 
4. **ë‹¤êµ­ì–´ í…ŒìŠ¤íŠ¸**: ë¹„ì˜ì–´ê¶Œ ì–¸ì–´ ê²€ì¦

## ğŸ¯ ê²°ë¡ 

pytorch_hmm v0.2.1ì€ **í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ** ìˆ˜ì¤€ì˜ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. **5ê°€ì§€ í•µì‹¬ ë¬¸ì œ í•´ê²°**ê³¼ **83% ì½”ë“œ ì»¤ë²„ë¦¬ì§€ í–¥ìƒ**ì„ í†µí•´ ì‹¤ì œ ìŒì„± ì²˜ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ê²¬ê³ í•œ ê¸°ë°˜ì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤.

íŠ¹íˆ **GPU ê°€ì†ì„ í†µí•œ 300x+ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„±ëŠ¥**ê³¼ **ë‹¤ì–‘í•œ HMM ëª¨ë¸ ì§€ì›**ì„ í†µí•´ ì „í†µì ì¸ í†µê³„ì  ìŒì„± ì²˜ë¦¬ì™€ í˜„ëŒ€ì ì¸ ë”¥ëŸ¬ë‹ ì ‘ê·¼ë²•ì˜ ê°€êµ ì—­í• ì„ í•˜ë©°, ìŒì„± í•©ì„± ê¸°ìˆ  ìŠ¤íƒì—ì„œ ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œë¡œ ìë¦¬ì¡ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

---

*ë¬¸ì„œ ì‘ì„±ì¼: 2025ë…„ 7ì›”*  
*ë¶„ì„ì: ìŒì„± í•©ì„± ê¸°ìˆ  ì „ë¬¸ê°€*
