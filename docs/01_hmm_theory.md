# 1. HMM 기초 이론

히든 마르코프 모델(Hidden Markov Model, HMM)은 시계열 데이터의 숨겨진 상태를 모델링하는 강력한 확률적 프레임워크입니다. 특히 음성 처리, 자연어 처리, 생물정보학 등 다양한 분야에서 널리 사용됩니다.

## 📚 목차

1. [HMM의 기본 개념](#hmm의-기본-개념)
2. [수학적 정의](#수학적-정의)
3. [HMM의 세 가지 기본 문제](#hmm의-세-가지-기본-문제)
4. [Forward-Backward 알고리즘](#forward-backward-알고리즘)
5. [Viterbi 알고리즘](#viterbi-알고리즘)
6. [Baum-Welch 알고리즘](#baum-welch-알고리즘)
7. [음성 처리에서의 HMM](#음성-처리에서의-hmm)

## HMM의 기본 개념

### 마르코프 가정

HMM은 두 가지 핵심 가정을 기반으로 합니다:

1. **마르코프 가정 (Markov Assumption)**: 현재 상태는 직전 상태에만 의존합니다.
   ```
   P(q_t | q_1, q_2, ..., q_{t-1}) = P(q_t | q_{t-1})
   ```

2. **출력 독립성 가정 (Output Independence)**: 관측값은 현재 상태에만 의존합니다.
   ```
   P(o_t | q_1, q_2, ..., q_T, o_1, o_2, ..., o_{t-1}) = P(o_t | q_t)
   ```

### HMM의 구조

```
   숨겨진 상태:  q_1 → q_2 → q_3 → ... → q_T
                  ↓    ↓    ↓         ↓
   관측 데이터:  o_1   o_2   o_3  ...  o_T
```

- **숨겨진 상태 (Hidden States)**: 직접 관측할 수 없는 내부 상태
- **관측 데이터 (Observations)**: 실제로 관측 가능한 데이터
- **전이 (Transitions)**: 상태 간의 변화
- **방출 (Emissions)**: 각 상태에서 관측값을 생성하는 과정

## 수학적 정의

HMM은 다음 5개의 구성 요소로 정의됩니다: **λ = (N, M, A, B, π)**

### 1. 상태 집합 (State Set)
- **N**: 숨겨진 상태의 개수
- **S = {S_1, S_2, ..., S_N}**: 상태 집합

### 2. 관측 기호 집합 (Observation Symbol Set)
- **M**: 관측 가능한 기호의 개수
- **V = {v_1, v_2, ..., v_M}**: 관측 기호 집합

### 3. 전이 확률 행렬 (Transition Probability Matrix)
```
A = [a_{ij}] where a_{ij} = P(q_{t+1} = S_j | q_t = S_i)
```

전이 행렬의 특성:
- **확률 조건**: 각 행의 합이 1 (∑_j a_{ij} = 1)
- **비음수**: 모든 원소가 0 이상 (a_{ij} ≥ 0)

### 4. 관측 확률 행렬 (Observation Probability Matrix)
```
B = [b_j(k)] where b_j(k) = P(o_t = v_k | q_t = S_j)
```

### 5. 초기 상태 확률 (Initial State Probability)
```
π = [π_i] where π_i = P(q_1 = S_i)
```

## HMM의 세 가지 기본 문제

### 문제 1: 평가 (Evaluation)
**주어진 것**: 모델 λ = (A, B, π)와 관측 시퀀스 O = o_1, o_2, ..., o_T  
**구하는 것**: P(O|λ) - 모델이 주어진 관측 시퀀스를 생성할 확률

**응용**: 
- 음성 인식에서 단어 모델 선택
- 패턴 분류 및 이상 탐지

### 문제 2: 디코딩 (Decoding)
**주어진 것**: 모델 λ와 관측 시퀀스 O  
**구하는 것**: 가장 가능성이 높은 숨겨진 상태 시퀀스 Q*

**응용**:
- 음성 합성에서 음소-음향 정렬
- 품사 태깅, 개체명 인식

### 문제 3: 학습 (Learning)
**주어진 것**: 관측 시퀀스 O  
**구하는 것**: P(O|λ)를 최대화하는 모델 매개변수 λ*

**응용**:
- 음성 인식 모델 훈련
- 언어 모델 학습

## Forward-Backward 알고리즘

### Forward 알고리즘

Forward 변수 α_t(i)는 시간 t까지의 관측 시퀀스와 시간 t에서 상태 i에 있을 확률을 나타냅니다.

**정의**:
```
α_t(i) = P(o_1, o_2, ..., o_t, q_t = S_i | λ)
```

**계산 과정**:

1. **초기화** (t = 1):
   ```
   α_1(i) = π_i × b_i(o_1), 1 ≤ i ≤ N
   ```

2. **유도** (2 ≤ t ≤ T):
   ```
   α_t(j) = [∑_{i=1}^N α_{t-1}(i) × a_{ij}] × b_j(o_t)
   ```

3. **종료**:
   ```
   P(O|λ) = ∑_{i=1}^N α_T(i)
   ```

### Backward 알고리즘

Backward 변수 β_t(i)는 시간 t에서 상태 i에 있고, 시간 t+1부터 T까지의 관측 시퀀스에 대한 확률입니다.

**정의**:
```
β_t(i) = P(o_{t+1}, o_{t+2}, ..., o_T | q_t = S_i, λ)
```

**계산 과정**:

1. **초기화** (t = T):
   ```
   β_T(i) = 1, 1 ≤ i ≤ N
   ```

2. **유도** (t = T-1, T-2, ..., 1):
   ```
   β_t(i) = ∑_{j=1}^N a_{ij} × b_j(o_{t+1}) × β_{t+1}(j)
   ```

### 상태 사후 확률 (Posterior Probability)

Forward와 Backward 확률을 결합하여 각 시점에서의 상태 확률을 계산:

```
γ_t(i) = P(q_t = S_i | O, λ) = (α_t(i) × β_t(i)) / P(O|λ)
```

## Viterbi 알고리즘

가장 가능성이 높은 상태 시퀀스를 찾는 동적 계획법 알고리즘입니다.

### 알고리즘 과정

1. **초기화** (t = 1):
   ```
   δ_1(i) = π_i × b_i(o_1)
   ψ_1(i) = 0
   ```

2. **유도** (2 ≤ t ≤ T):
   ```
   δ_t(j) = max_i [δ_{t-1}(i) × a_{ij}] × b_j(o_t)
   ψ_t(j) = argmax_i [δ_{t-1}(i) × a_{ij}]
   ```

3. **종료**:
   ```
   P* = max_i δ_T(i)
   q_T* = argmax_i δ_T(i)
   ```

4. **역추적** (t = T-1, T-2, ..., 1):
   ```
   q_t* = ψ_{t+1}(q_{t+1}*)
   ```

### Forward-Backward vs Viterbi 비교

| 특성 | Forward-Backward | Viterbi |
|------|------------------|---------|
| **출력** | 소프트 확률 분포 | 하드 상태 시퀀스 |
| **계산 복잡도** | O(N²T) | O(N²T) |
| **용도** | 훈련, 불확실성 정량화 | 추론, 디코딩 |
| **정보량** | 모든 가능한 경로 고려 | 최적 경로만 고려 |

## Baum-Welch 알고리즘

HMM 매개변수를 학습하는 EM(Expectation-Maximization) 알고리즘입니다.

### E-step: 기댓값 계산

1. **상태 점유 확률**:
   ```
   γ_t(i) = (α_t(i) × β_t(i)) / P(O|λ)
   ```

2. **전이 확률**:
   ```
   ξ_t(i,j) = (α_t(i) × a_{ij} × b_j(o_{t+1}) × β_{t+1}(j)) / P(O|λ)
   ```

### M-step: 매개변수 업데이트

1. **초기 상태 확률**:
   ```
   π̂_i = γ_1(i)
   ```

2. **전이 확률**:
   ```
   â_{ij} = (∑_{t=1}^{T-1} ξ_t(i,j)) / (∑_{t=1}^{T-1} γ_t(i))
   ```

3. **관측 확률**:
   ```
   b̂_j(k) = (∑_{t=1,o_t=v_k}^T γ_t(j)) / (∑_{t=1}^T γ_t(j))
   ```

## 음성 처리에서의 HMM

### 음성 합성 (TTS)에서의 활용

1. **텍스트-음성 정렬**:
   - 음소 시퀀스를 음향 특징으로 매핑
   - 각 음소를 여러 상태로 모델링 (시작-중간-끝)

2. **지속시간 모델링**:
   - 각 음소의 발음 길이 제어
   - 운율 정보 반영

```python
# 음성 합성에서의 HMM 사용 예시
phoneme_sequence = ["sil", "h", "e", "l", "l", "o", "sil"]
states_per_phoneme = 3  # 시작-중간-끝
total_states = len(phoneme_sequence) * states_per_phoneme

# Left-to-right 전이 행렬 생성
P = create_left_to_right_matrix(total_states, self_loop_prob=0.7)
```

### 음성 인식 (ASR)에서의 활용

1. **음향 모델링**:
   - 음소별 음향 특징 분포 모델링
   - 컨텍스트 의존 모델 (triphone)

2. **강제 정렬**:
   - 음성과 텍스트의 시간 정렬
   - 음소 경계 검출

### 음성 특징과 관측 모델

1. **연속 관측 모델**:
   - 가우시안 분포: 단일 가우시안 또는 혼합 가우시안
   - 멜 스펙트로그램, MFCC 등의 특징 사용

2. **이산 관측 모델**:
   - 벡터 양자화된 특징
   - 코드북 기반 모델링

### 실제 구현 고려사항

1. **수치적 안정성**:
   - 로그 확률 사용으로 언더플로우 방지
   - 정규화 및 스케일링

2. **계산 효율성**:
   - 희소 전이 행렬 활용
   - 병렬 처리 및 GPU 가속

3. **모델 복잡도**:
   - 상태 수와 관측 차원의 균형
   - 과적합 방지를 위한 정규화

## 다음 단계

이제 HMM의 기본 이론을 이해했다면, [기본 사용법](02_basic_usage.md)에서 PyTorch HMM 라이브러리를 사용하여 실제로 구현해보겠습니다.

**주요 학습 내용**:
- ✅ HMM의 기본 개념과 구조
- ✅ 수학적 정의와 세 가지 기본 문제
- ✅ Forward-Backward, Viterbi, Baum-Welch 알고리즘
- ✅ 음성 처리에서의 HMM 활용 방법

**다음 학습 목표**:
- PyTorch HMM 라이브러리 설치 및 설정
- 첫 번째 HMM 모델 생성과 추론
- 신경망과의 통합 방법 