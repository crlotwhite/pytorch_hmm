# ğŸ¯ PyTorch HMM v0.2.0 - ìŒì„± í•©ì„±ì— íŠ¹í™”ëœ Hidden Markov Model

[![CI](https://github.com/crlotwhite/pytorch_hmm/workflows/CI/badge.svg)](https://github.com/crlotwhite/pytorch_hmm/actions)
[![codecov](https://codecov.io/gh/crlotwhite/pytorch_hmm/branch/main/graph/badge.svg)](https://codecov.io/gh/crlotwhite/pytorch_hmm)
[![PyPI version](https://badge.fury.io/py/pytorch-hmm.svg)](https://badge.fury.io/py/pytorch-hmm)
[![Python versions](https://img.shields.io/pypi/pyversions/pytorch-hmm.svg)](https://pypi.org/project/pytorch-hmm/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

PyTorch ê¸°ë°˜ Hidden Markov Model êµ¬í˜„ì²´ë¡œ, **ìŒì„± í•©ì„±(TTS)ê³¼ ìŒì„± ì²˜ë¦¬**ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Forward-backwardì™€ Viterbi ì•Œê³ ë¦¬ì¦˜ì„ ì§€ì›í•˜ë©°, autogradì™€ GPU ê°€ì†ì„ ì™„ë²½í•˜ê²Œ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸš€ v0.2.0 ì£¼ìš” ê¸°ëŠ¥

### âœ¨ ìƒˆë¡œìš´ ëª¨ë¸ë“¤
- ğŸ¨ **MixtureGaussianHMM**: ë³µì¡í•œ ìŒí–¥ ëª¨ë¸ë§ì„ ìœ„í•œ GMM-HMM
- â° **Semi-Markov Model (HSMM)**: ëª…ì‹œì  ì§€ì†ì‹œê°„ ëª¨ë¸ë§
- ğŸ“¡ **StreamingHMM**: ì‹¤ì‹œê°„ ë‚®ì€ ì§€ì—°ì‹œê°„ ì²˜ë¦¬
- ğŸ”„ **AdaptiveTransitions**: ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë™ì  ì „ì´

### ğŸ¯ ìŒì„± ì²˜ë¦¬ íŠ¹í™” ê¸°ëŠ¥
- ğŸ‡°ğŸ‡· **í•œêµ­ì–´ TTS ì§€ì›**: ìŒì†Œ ì •ë ¬ê³¼ ì§€ì†ì‹œê°„ ì œì–´
- ğŸµ **ìš´ìœ¨ ì¸ì‹ ì „ì´**: F0ì™€ ì—ë„ˆì§€ ê¸°ë°˜ ì „ì´ í–‰ë ¬
- âš¡ **Skip-state ì „ì´**: ë¹ ë¥¸ ë°œí™” ì²˜ë¦¬
- ğŸ“Š **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹**: ì¢…í•©ì ì¸ ì„±ëŠ¥ ë¶„ì„ ë„êµ¬

### ğŸ’» í”„ë¡œë•ì…˜ ì¤€ë¹„
- ğŸ­ **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
- ğŸ”§ **TorchScript ì§€ì›**: ë°°í¬ ìµœì í™”
- ğŸ“ˆ **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ì„±ëŠ¥ í†µê³„ ë° ì ì‘í˜• ì œì–´
- ğŸ§ª **ì¢…í•© í…ŒìŠ¤íŠ¸**: 95%+ ì½”ë“œ ì»¤ë²„ë¦¬ì§€

## ğŸ“¦ ì„¤ì¹˜

```bash
# ê¸°ë³¸ ì„¤ì¹˜
pip install pytorch-hmm

# ìŒì„± ì²˜ë¦¬ ê¸°ëŠ¥ í¬í•¨
pip install pytorch-hmm[audio]

# ì „ì²´ ê¸°ëŠ¥ (ê°œë°œìš©)
pip install pytorch-hmm[all]

# ê°œë°œ ë²„ì „
git clone https://github.com/crlotwhite/pytorch_hmm.git
cd pytorch_hmm
pip install -e .[dev]
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ê¸°ë³¸ HMM ì‚¬ìš©ë²•

```python
import torch
from pytorch_hmm import create_speech_hmm, get_speech_transitions

# ìŒì„±ìš© HMM ìƒì„±
model = create_speech_hmm(
    num_states=10,      # ìŒì†Œ ê°œìˆ˜
    feature_dim=80,     # ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì°¨ì›
    model_type="mixture_gaussian"
)

# ìŒì„± íŠ¹ì§• ë°ì´í„°
features = torch.randn(4, 100, 80)  # (batch, time, features)

# ë””ì½”ë”©
decoded_states, log_probs = model(features, return_log_probs=True)
print(f"ë””ì½”ë”©ëœ ìƒíƒœ: {decoded_states.shape}")  # (4, 100)
```

### ğŸ¨ Mixture Gaussian HMM

```python
from pytorch_hmm import MixtureGaussianHMMLayer

# ë³µì¡í•œ ìŒí–¥ ëª¨ë¸ë§
model = MixtureGaussianHMMLayer(
    num_states=20,          # 20ê°œ ìŒì†Œ
    feature_dim=80,         # 80ì°¨ì› ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨  
    num_components=4,       # 4ê°œ ê°€ìš°ì‹œì•ˆ ë¯¹ìŠ¤ì²˜
    covariance_type='diag'  # ëŒ€ê° ê³µë¶„ì‚°
)

# ìŒí–¥ íŠ¹ì§• ì²˜ë¦¬
audio_features = torch.randn(2, 150, 80)
states, confidence = model(audio_features, return_log_probs=True)

print(f"ëª¨ë¸ ì •ë³´: {model.get_model_info()}")
```

### â° Semi-Markov Model (HSMM)

```python
from pytorch_hmm import HSMMLayer

# ì§€ì†ì‹œê°„ ëª¨ë¸ë§
hsmm = HSMMLayer(
    num_states=15,
    feature_dim=80,
    duration_distribution='gamma',  # Gamma ë¶„í¬
    max_duration=50                 # ìµœëŒ€ 50í”„ë ˆì„
)

# ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ì‹œí€€ìŠ¤ ìƒì„±
states, observations = hsmm.generate_sequence(length=200)

# ì§€ì†ì‹œê°„ ë¶„ì„
expected_durations = hsmm.get_expected_durations()
print(f"ê° ìƒíƒœì˜ ì˜ˆìƒ ì§€ì†ì‹œê°„: {expected_durations}")
```

### ğŸ“¡ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°

```python
from pytorch_hmm import StreamingHMMProcessor, AdaptiveLatencyController

# ì‹¤ì‹œê°„ í”„ë¡œì„¸ì„œ
processor = StreamingHMMProcessor(
    num_states=10,
    feature_dim=80,
    chunk_size=160,         # 10ms ì²­í¬
    use_beam_search=True,
    beam_width=4
)

# ì ì‘í˜• ì§€ì—°ì‹œê°„ ì œì–´
controller = AdaptiveLatencyController(target_latency_ms=30.0)

# ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
for i in range(100):
    # 10ms ì˜¤ë””ì˜¤ ì²­í¬
    audio_chunk = torch.randn(160, 80)
    
    # ì²˜ë¦¬
    result = processor.process_chunk(audio_chunk)
    
    if result.status == 'decoded':
        print(f"ìƒíƒœ: {result.decoded_states}")
        print(f"ì²˜ë¦¬ ì‹œê°„: {result.processing_time_ms:.1f}ms")
        
        # ì„±ëŠ¥ ì ì‘
        recommendations = controller.update(
            result.processing_time_ms, 
            result.buffer_size
        )
```

### ğŸ‡°ğŸ‡· í•œêµ­ì–´ TTS ì˜ˆì‹œ

```python
from pytorch_hmm import create_korean_tts_hmm

# í•œêµ­ì–´ ìŒì†Œ ì§‘í•©ìœ¼ë¡œ HMM ìƒì„±
korean_model = create_korean_tts_hmm(
    feature_dim=80,
    model_type="hsmm"  # ì§€ì†ì‹œê°„ ëª¨ë¸ë§ í¬í•¨
)

# ìŒì†Œ ì‹œí€€ìŠ¤: "ì•ˆë…•í•˜ì„¸ìš”"
phoneme_sequence = ['sil', 'a', 'n', 'n', 'eo', 'ng', 'h', 'a', 's', 'e', 'j', 'o', 'sil']

print(f"í•œêµ­ì–´ HMM ì •ë³´:")
print(f"  ìƒíƒœ ìˆ˜: {korean_model.num_states}")
print(f"  íŠ¹ì§• ì°¨ì›: {korean_model.feature_dim}")
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### ì „ì´ í–‰ë ¬ ì»¤ìŠ¤í„°ë§ˆì´ì§•

```python
from pytorch_hmm.utils import (
    create_skip_state_matrix,
    create_phoneme_aware_transitions,
    create_prosody_aware_transitions
)

# ë¹ ë¥¸ ë°œí™”ìš© Skip-state ì „ì´
skip_transitions = create_skip_state_matrix(
    num_states=20,
    self_loop_prob=0.5,    # ë‚®ì€ ìœ ì§€ í™•ë¥ 
    forward_prob=0.4,      # ë†’ì€ ì „ì§„ í™•ë¥   
    skip_prob=0.1,         # ê±´ë„ˆë›°ê¸° í—ˆìš©
    max_skip=2
)

# ìŒì†Œ ì§€ì†ì‹œê°„ ê¸°ë°˜ ì „ì´
phoneme_durations = [5, 8, 6, 12, 4, 9, 7, 11]  # ê° ìŒì†Œë³„ í‰ê·  ì§€ì†ì‹œê°„
duration_transitions = create_phoneme_aware_transitions(
    phoneme_durations,
    duration_variance=0.3
)

# ìš´ìœ¨ ì •ë³´ ê¸°ë°˜ ë™ì  ì „ì´
f0_contour = torch.randn(100)      # F0 ìœ¤ê³½
energy_contour = torch.randn(100)  # ì—ë„ˆì§€ ìœ¤ê³½

prosody_transitions = create_prosody_aware_transitions(
    f0_contour, energy_contour, num_states=10
)
print(f"ìš´ìœ¨ ê¸°ë°˜ ì „ì´ í–‰ë ¬: {prosody_transitions.shape}")  # (100, 10, 10)
```

### ì„±ëŠ¥ ìµœì í™”

```python
import pytorch_hmm

# í•˜ë“œì›¨ì–´ ìë™ ì„¤ì •
config_info = pytorch_hmm.auto_configure()
print(f"ìë™ ì„¤ì •: {config_info}")

# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
from pytorch_hmm.utils import benchmark_transition_operations

benchmark_results = benchmark_transition_operations(
    num_states_list=[5, 10, 20, 50],
    num_trials=100
)

for operation, results in benchmark_results.items():
    print(f"{operation}:")
    for num_states, time_ms in results.items():
        print(f"  {num_states} states: {time_ms:.2f}ms")
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ì²˜ë¦¬ ì†ë„ (RTX 3080 ê¸°ì¤€)
- **MixtureGaussianHMM**: ~18,000 frames/sec
- **HSMM**: ~12,000 frames/sec  
- **StreamingHMM**: ~25,000 frames/sec
- **ì‹¤ì‹œê°„ ë°°ìœ¨**: 150-400x (ì‹¤ì‹œê°„ 80fps ê¸°ì¤€)

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- **ëŒ€ìš©ëŸ‰ ë°°ì¹˜**: 32 sequences Ã— 2000 frames ì²˜ë¦¬ ê°€ëŠ¥
- **GPU ë©”ëª¨ë¦¬**: 2GB ì´í•˜ (ëŒ€ë¶€ë¶„ì˜ ì‘ì—…)
- **ìŠ¤íŠ¸ë¦¬ë°**: ì¼ì •í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (<100MB)

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ë¹ ë¥¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
pytest tests/ -m "not slow"

# ì „ì²´ í…ŒìŠ¤íŠ¸ (ì‹œê°„ ì†Œìš”)
pytest tests/ --cov=pytorch_hmm

# GPU í…ŒìŠ¤íŠ¸
pytest tests/ -m gpu

# ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
pytest tests/ -m performance --benchmark-only

# íŒ¨í‚¤ì§€ ë¬´ê²°ì„± í™•ì¸
python -c "import pytorch_hmm; pytorch_hmm.run_quick_test()"
```

## ğŸ“š ë¬¸ì„œ ë° ì˜ˆì‹œ

- ğŸ“– **API ë¬¸ì„œ**: [pytorch-hmm.readthedocs.io](https://pytorch-hmm.readthedocs.io)
- ğŸ’¡ **íŠœí† ë¦¬ì–¼**: [examples/](examples/) ë””ë ‰í† ë¦¬
- ğŸµ **ìŒì„± ì²˜ë¦¬ ì˜ˆì‹œ**: [examples/speech_synthesis_examples.py](examples/speech_synthesis_examples.py)
- ğŸ‡°ğŸ‡· **í•œêµ­ì–´ TTS ë°ëª¨**: [examples/korean_tts_demo.py](examples/korean_tts_demo.py)
- âš¡ **ì‹¤ì‹œê°„ ì²˜ë¦¬**: [examples/real_time_processing.py](examples/real_time_processing.py)

## ğŸ› ï¸ ê°œë°œ ì°¸ì—¬

```bash
# ê°œë°œ í™˜ê²½ ì„¤ì •
git clone https://github.com/crlotwhite/pytorch_hmm.git
cd pytorch_hmm
pip install -e .[dev]

# ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬
pre-commit install
black pytorch_hmm tests
isort pytorch_hmm tests
flake8 pytorch_hmm tests
mypy pytorch_hmm

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/ -v
```

## ğŸ“ˆ ë¡œë“œë§µ

### v0.3.0 (ì˜ˆì •)
- ğŸ­ **ê°ì • ìŒì„± í•©ì„±**: ê°ì • ìƒíƒœ ê¸°ë°˜ HMM
- ğŸŒ **ë‹¤êµ­ì–´ ì§€ì›**: ì˜ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´ ìŒì†Œ ì§‘í•©
- ğŸ”Š **í™”ì ì ì‘**: ë‹¤ì¤‘ í™”ì ëª¨ë¸ë§
- ğŸ¯ **ê³ ê¸‰ ì •ë ¬**: DTWì™€ HMM ê²°í•© ì •ë ¬

### v1.0.0 (ëª©í‘œ)
- ğŸ­ **í”„ë¡œë•ì…˜ ì•ˆì •ì„±**: API ê³ ì • ë° í•˜ìœ„ í˜¸í™˜ì„±
- ğŸ“¦ **íŒ¨í‚¤ì§€ ìƒíƒœê³„**: Hugging Face, PyTorch Lightning í†µí•©
- ğŸš€ **ë°°í¬ ìµœì í™”**: ONNX, TensorRT ì§€ì›
- ğŸ“š **ì™„ì „í•œ ë¬¸ì„œí™”**: ì¢…í•© ê°€ì´ë“œ ë° íŠœí† ë¦¬ì–¼

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

PyTorch HMM í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•´ì£¼ì„¸ìš”! 

- ğŸ› **ë²„ê·¸ ë¦¬í¬íŠ¸**: [Issues](https://github.com/crlotwhite/pytorch_hmm/issues)
- ğŸ’¡ **ê¸°ëŠ¥ ì œì•ˆ**: [Discussions](https://github.com/crlotwhite/pytorch_hmm/discussions)
- ğŸ”§ **Pull Request**: [Contributing Guide](CONTRIBUTING.md)

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ™ ê°ì‚¬ì˜ ë§

- **PyTorch íŒ€**: í›Œë¥­í•œ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- **ìŒì„± ì²˜ë¦¬ ì»¤ë®¤ë‹ˆí‹°**: ê·€ì¤‘í•œ í”¼ë“œë°±ê³¼ ì œì•ˆ
- **ëª¨ë“  ê¸°ì—¬ìë“¤**: ì½”ë“œ, ë¬¸ì„œ, í…ŒìŠ¤íŠ¸ ê¸°ì—¬

---

â­ **ì´ í”„ë¡œì íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´ Starë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!** â­
