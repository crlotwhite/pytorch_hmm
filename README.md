# PyTorch HMM

ğŸ¯ **ìŒì„± í•©ì„±ì— íŠ¹í™”ëœ PyTorch Hidden Markov Model ë¼ì´ë¸ŒëŸ¬ë¦¬**

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 1.8+](https://img.shields.io/badge/PyTorch-1.8+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

PyTorch ê¸°ë°˜ Hidden Markov Model êµ¬í˜„ì²´ë¡œ, **ìŒì„± í•©ì„±(TTS)ê³¼ ìŒì„± ì²˜ë¦¬ ì‘ìš©**ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Forward-backwardì™€ Viterbi ì•Œê³ ë¦¬ì¦˜ì„ ì§€ì›í•˜ë©°, autogradì™€ GPU ê°€ì†ì„ ì™„ë²½í•˜ê²Œ ì§€ì›í•©ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” íŠ¹ì§•

### ğŸš€ **ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±**
- **PyTorch Native**: ì™„ì „í•œ autograd ì§€ì›ê³¼ GPU ê°€ì†
- **ë°°ì¹˜ ì²˜ë¦¬**: íš¨ìœ¨ì ì¸ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
- **Numerical Stability**: Log-space ê³„ì‚°ìœ¼ë¡œ ìˆ˜ì¹˜ì  ì•ˆì •ì„± í™•ë³´
- **ì‹¤ì‹œê°„ ì¶”ë¡ **: ìµœì í™”ëœ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥

### ğŸµ **ìŒì„± í•©ì„± ìµœì í™”**
- **ìŒì†Œ ì •ë ¬**: í…ìŠ¤íŠ¸-ìŒì„± ì •ë ¬ì„ ìœ„í•œ ì „ë¬¸ ë„êµ¬
- **ì§€ì†ì‹œê°„ ëª¨ë¸ë§**: ìì—°ìŠ¤ëŸ¬ìš´ ìŒì†Œ ì§€ì†ì‹œê°„ ì œì–´
- **Left-to-right HMM**: ìŒì„± ì‹ í˜¸ì˜ ì‹œê°„ì  íŠ¹ì„±ì— ë§ëŠ” ëª¨ë¸
- **ê°€ìš°ì‹œì•ˆ ê´€ì¸¡ ëª¨ë¸**: ì—°ì†ì ì¸ ìŒí–¥ íŠ¹ì§• ì²˜ë¦¬

### ğŸ”§ **ê°œë°œì ì¹œí™”ì **
- **nn.Module í†µí•©**: ê¸°ì¡´ PyTorch ëª¨ë¸ì— ì‰½ê²Œ í†µí•©
- **ìœ ì—°í•œ Transition Matrix**: ë‹¤ì–‘í•œ ì‘ìš©ì— ë§ëŠ” ì „ì´ íŒ¨í„´
- **ìƒì„¸í•œ ë¬¸ì„œí™”**: íŠœí† ë¦¬ì–¼ê³¼ ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ ì œê³µ

## ğŸ“¦ ì„¤ì¹˜

```bash
pip install pytorch-hmm
```

ë˜ëŠ” ê°œë°œ ë²„ì „:

```bash
git clone https://github.com/crlotwhite/pytorch_hmm.git
cd pytorch_hmm
pip install -e .
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ê¸°ë³¸ HMM ì‚¬ìš©ë²•

```python
import torch
from pytorch_hmm import HMMPyTorch, create_left_to_right_matrix

# Left-to-right HMM ìƒì„± (ìŒì„± í•©ì„±ì— ì¼ë°˜ì )
num_states = 5
transition_matrix = create_left_to_right_matrix(num_states, self_loop_prob=0.8)
hmm = HMMPyTorch(transition_matrix)

# ê´€ì¸¡ ë°ì´í„° (batch_size=2, seq_len=10, num_states=5)
observations = torch.rand(2, 10, 5)

# Forward-backward ì•Œê³ ë¦¬ì¦˜
posterior, forward, backward = hmm.forward_backward(observations)

# Viterbi ë””ì½”ë”©
states, scores = hmm.viterbi_decode(observations)

print(f"Posterior shape: {posterior.shape}")  # (2, 10, 5)
print(f"Optimal states: {states[0]}")         # ì²« ë²ˆì§¸ ì‹œí€€ìŠ¤ì˜ ìµœì  ìƒíƒœ ê²½ë¡œ
```

### ì‹ ê²½ë§ê³¼ì˜ í†µí•©

```python
import torch.nn as nn
from pytorch_hmm import HMMLayer

class SpeechSynthesisModel(nn.Module):
    def __init__(self, input_dim, num_phonemes):
        super().__init__()
        
        # íŠ¹ì§• ì¶”ì¶œê¸°
        self.feature_net = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, num_phonemes)
        )
        
        # HMM ì •ë ¬ ë ˆì´ì–´
        self.hmm_layer = HMMLayer(
            num_states=num_phonemes,
            learnable_transitions=True,  # í•™ìŠµ ê°€ëŠ¥í•œ ì „ì´ í™•ë¥ 
            transition_type="left_to_right"
        )
    
    def forward(self, linguistic_features):
        # ì–¸ì–´ì  íŠ¹ì§•ì„ ìŒì†Œ í™•ë¥ ë¡œ ë³€í™˜
        phoneme_probs = self.feature_net(linguistic_features)
        
        # HMMìœ¼ë¡œ ì‹œê°„ ì •ë ¬ ìˆ˜í–‰
        aligned_phonemes = self.hmm_layer(phoneme_probs)
        
        return aligned_phonemes

# ëª¨ë¸ ì‚¬ìš©
model = SpeechSynthesisModel(input_dim=256, num_phonemes=50)
linguistic_input = torch.randn(4, 20, 256)  # (batch, time, features)
aligned_output = model(linguistic_input)
```

## ğŸ“š ìƒì„¸ ì‚¬ìš©ë²•

### 1. Transition Matrix ìƒì„±

```python
from pytorch_hmm import create_transition_matrix

# ë‹¤ì–‘í•œ íƒ€ì…ì˜ ì „ì´ í–‰ë ¬
ergodic_matrix = create_transition_matrix(5, "ergodic")           # ì™„ì „ ì—°ê²°
left_right = create_transition_matrix(5, "left_to_right")         # ìˆœì°¨ ì§„í–‰
skip_matrix = create_transition_matrix(5, "left_to_right_skip")   # ìƒíƒœ ê±´ë„ˆë›°ê¸° í—ˆìš©
circular = create_transition_matrix(5, "circular")               # ìˆœí™˜ êµ¬ì¡°
```
ìƒì„±ëœ ì „ì´ í–‰ë ¬ì€ ê° í–‰ì´ 1ë¡œ ì •ê·œí™”ëœ í™•ë¥  ë¶„í¬ì…ë‹ˆë‹¤.

### 2. ê°€ìš°ì‹œì•ˆ HMM (ì—°ì† íŠ¹ì§•ìš©)

```python
from pytorch_hmm import GaussianHMMLayer

# ì—°ì†ì ì¸ ìŒí–¥ íŠ¹ì§•ì„ ìœ„í•œ ê°€ìš°ì‹œì•ˆ HMM
gaussian_hmm = GaussianHMMLayer(
    num_states=10,
    feature_dim=80,  # ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì°¨ì›
    covariance_type='diag'
)

# MFCCë‚˜ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ê°™ì€ ì—°ì† íŠ¹ì§•
acoustic_features = torch.randn(3, 100, 80)  # (batch, time, mfcc_dim)
posteriors = gaussian_hmm(acoustic_features)
```

### 3. ìŒì„± í•©ì„± íŒŒì´í”„ë¼ì¸

```python
from pytorch_hmm.utils import compute_state_durations

# 1. ìŒì†Œ ì‹œí€€ìŠ¤ ì •ë ¬
phoneme_sequence = ["sil", "a", "n", "n", "y", "eo", "ng", "sil"]
hmm = create_phoneme_hmm(phoneme_sequence)

# 2. ìŒí–¥ íŠ¹ì§•ê³¼ ì •ë ¬
acoustic_features = load_audio_features("hello.wav")
aligned_states, _ = hmm.align(acoustic_features)

# 3. ì§€ì†ì‹œê°„ ê³„ì‚°
durations = compute_state_durations(aligned_states)
print(f"ê° ìŒì†Œì˜ ì§€ì†ì‹œê°„: {durations}")

# 4. ìƒˆë¡œìš´ ìŒì„± í•©ì„± ì‹œ ì§€ì†ì‹œê°„ ì¡°ì ˆ
new_durations = durations * 1.2  # 20% ëŠë¦¬ê²Œ
synthesized_audio = synthesize_with_durations(phoneme_sequence, new_durations)
```

## ğŸ¯ ìŒì„± í•©ì„± ì‘ìš© ì˜ˆì œ

### ìŒì†Œ-ìŒí–¥ ì •ë ¬

```python
# í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œëœ ìŒì†Œ ì‹œí€€ìŠ¤
phonemes = ["sil", "ì•ˆ", "ë…•", "í•˜", "ì„¸", "ìš”", "sil"]

# ìŒì„± íŒŒì¼ì—ì„œ ì¶”ì¶œëœ ìŒí–¥ íŠ¹ì§• (MFCC, ë©œìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë“±)
audio_features = extract_acoustic_features("audio.wav")

# HMMìœ¼ë¡œ ì •ë ¬ ìˆ˜í–‰
alignment_model = create_alignment_model(len(phonemes))
phoneme_boundaries = alignment_model.align(phonemes, audio_features)

print("ìŒì†Œë³„ ì‹œì‘-ë ì‹œê°„:")
for phoneme, (start, end) in zip(phonemes, phoneme_boundaries):
    print(f"{phoneme}: {start:.2f}s - {end:.2f}s")
```

### ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ë””ì½”ë”©

```python
# ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìŒì„± ì¸ì‹
streaming_hmm = HMMLayer(
    num_states=num_phonemes,
    viterbi_inference=True,  # ë¹ ë¥¸ í•˜ë“œ ë””ì½”ë”©
    learnable_transitions=False  # ê³ ì •ëœ ì–¸ì–´ ëª¨ë¸
)

# ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
chunk_size = 160  # 10ms @ 16kHz
for audio_chunk in audio_stream:
    features = extract_features(audio_chunk)
    phoneme_probs = acoustic_model(features)
    decoded_phonemes = streaming_hmm(phoneme_probs)
    
    # ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶œë ¥
    update_transcription(decoded_phonemes)
```

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### ì‚¬ìš©ì ì •ì˜ Transition Matrix

```python
import torch
from pytorch_hmm import HMMPyTorch

# íŠ¹ë³„í•œ ì œì•½ì´ ìˆëŠ” ì „ì´ í–‰ë ¬ ìƒì„±
def create_custom_transition_matrix(num_states, min_duration=3):
    """ê° ìƒíƒœì—ì„œ ìµœì†Œ ì§€ì†ì‹œê°„ì„ ë³´ì¥í•˜ëŠ” ì „ì´ í–‰ë ¬"""
    P = torch.zeros(num_states, num_states)
    
    for i in range(num_states):
        if i < num_states - 1:
            P[i, i] = 0.9      # ë†’ì€ self-loop í™•ë¥ 
            P[i, i + 1] = 0.1  # ë‚®ì€ ì „ì§„ í™•ë¥ 
        else:
            P[i, i] = 1.0      # ë§ˆì§€ë§‰ ìƒíƒœëŠ” ìœ ì§€
    
    return P

# ì‚¬ìš©ì ì •ì˜ HMM
custom_P = create_custom_transition_matrix(10)
hmm = HMMPyTorch(custom_P)
```

### ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„° íš¨ìœ¨ì  ì²˜ë¦¬
def process_large_dataset(dataset, batch_size=32):
    hmm = HMMPyTorch(transition_matrix).cuda()  # GPU ì‚¬ìš©
    
    results = []
    for batch in DataLoader(dataset, batch_size=batch_size):
        with torch.no_grad():  # ë©”ëª¨ë¦¬ ì ˆì•½
            observations = batch.cuda()
            posteriors, _, _ = hmm.forward_backward(observations)
            results.append(posteriors.cpu())
    
    return torch.cat(results, dim=0)
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

```python
# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python examples/benchmark.py
```

ì¼ë°˜ì ì¸ ì„±ëŠ¥ (RTX 3080 GPU ê¸°ì¤€):
- **Forward-Backward**: ~15,000 frames/sec
- **Viterbi**: ~25,000 frames/sec  
- **HMM Layer**: ~12,000 frames/sec

ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬ (80fps)ì— ëŒ€í•´ **150-300x** ë¹ ë¥¸ ì†ë„ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python -m pytest tests/ -v

# ì»¤ë²„ë¦¬ì§€ í¬í•¨
python -m pytest tests/ --cov=pytorch_hmm --cov-report=html

# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
python -m pytest tests/test_hmm.py::TestHMMPyTorch::test_forward_backward -v
```

## ğŸ“– ì˜ˆì œì™€ íŠœí† ë¦¬ì–¼

### ê¸°ë³¸ íŠœí† ë¦¬ì–¼
```bash
python examples/basic_tutorial.py
```

### ìŒì„± í•©ì„± ì˜ˆì œ
```bash
python examples/speech_synthesis_examples.py
```

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
```bash
python examples/benchmark.py
```

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### ê°œë°œ í™˜ê²½ ì„¤ì •

```bash
git clone https://github.com/crlotwhite/pytorch_hmm.git
cd pytorch_hmm

# ê°œë°œìš© ì˜ì¡´ì„± ì„¤ì¹˜
pip install -e ".[dev]"

# ì½”ë“œ ìŠ¤íƒ€ì¼ ê²€ì‚¬
black pytorch_hmm/
flake8 pytorch_hmm/
isort pytorch_hmm/

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“š ì°¸ê³  ìë£Œ

### HMM ì´ë¡ 
- Rabiner, L. R. (1989). "A tutorial on hidden Markov models and selected applications in speech recognition"
- Jelinek, F. (1997). "Statistical methods for speech recognition"

### ìŒì„± í•©ì„± ì‘ìš©
- Zen, H., et al. (2009). "Statistical parametric speech synthesis using deep neural networks"
- Wang, Y., et al. (2017). "Tacotron: Towards end-to-end speech synthesis"

### PyTorchì™€ ë”¥ëŸ¬ë‹
- [PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/)
- [Deep Learning Book](https://www.deeplearningbook.org/)

## ğŸ™‹â€â™‚ï¸ ì§€ì›

- **ì´ìŠˆ**: [GitHub Issues](https://github.com/crlotwhite/pytorch_hmm/issues)
- **í† ë¡ **: [GitHub Discussions](https://github.com/crlotwhite/pytorch_hmm/discussions)
- **ë¬¸ì„œ**: [Wiki](https://github.com/crlotwhite/pytorch_hmm/wiki)

## ğŸ“ˆ ë¡œë“œë§µ

- [ ] **v0.2.0**: 
  - Continuous HMM ì§€ì› í™•ì¥
  - ë” ë§ì€ Transition matrix íƒ€ì…
  - ì„±ëŠ¥ ìµœì í™”

- [ ] **v0.3.0**:
  - Semi-Markov Models ì§€ì›
  - ê³ ê¸‰ ìŒì„± í•©ì„± ìœ í‹¸ë¦¬í‹°
  - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”

- [ ] **v1.0.0**:
  - ì•ˆì •í™”ëœ API
  - ì™„ì „í•œ ë¬¸ì„œí™”
  - í”„ë¡œë•ì…˜ ë ˆë””

---

â­ **ì´ í”„ë¡œì íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´ Starë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!**

ğŸ”— **ê´€ë ¨ í”„ë¡œì íŠ¸**: [Original TensorFlow HMM](https://github.com/crlotwhite/tensorflow_hmm)
