#!/usr/bin/env python3
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "torch>=1.12.0",
#     "numpy>=1.21.0",
#     "matplotlib>=3.5.0",
# ]
# ///
"""
PyTorch HMM Basic Tutorial

ì´ íŠœí† ë¦¬ì–¼ì€ PyTorch HMM ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ê¸°ë³¸ ì‚¬ìš©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
ìŒì„± í•©ì„±ê³¼ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ì˜ ê¸°ì´ˆë¶€í„° ê³ ê¸‰ ê¸°ëŠ¥ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ëª©ì°¨:
1. ê¸°ë³¸ HMM ì‚¬ìš©ë²•
2. Forward-backward vs Viterbi ë¹„êµ
3. HMMLayerë¥¼ ì´ìš©í•œ ì‹ ê²½ë§ í†µí•©
4. ë°°ì¹˜ ì²˜ë¦¬
5. GPU ì‚¬ìš©ë²•
6. ì‹¤ì œ ì‘ìš© ì˜ˆì œ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List
import time

# PyTorch HMM import
from pytorch_hmm import (
    HMMPyTorch, HMMLayer, GaussianHMMLayer,
    create_left_to_right_matrix, create_transition_matrix,
    compute_state_durations
)

def tutorial_1_basic_hmm():
    """íŠœí† ë¦¬ì–¼ 1: ê¸°ë³¸ HMM ì‚¬ìš©ë²•"""
    print("=" * 60)
    print("ğŸ“š Tutorial 1: Basic HMM Usage")
    print("=" * 60)

    # Step 1: Transition matrix ìƒì„±
    print("\n1. Creating transition matrix...")
    num_states = 5

    # Left-to-right transition matrix (ìŒì„± í•©ì„±ì—ì„œ ì¼ë°˜ì )
    P = create_left_to_right_matrix(num_states, self_loop_prob=0.7)
    print(f"   Transition matrix shape: {P.shape}")
    print(f"   Self-loop probability: 0.7")

    # ì „ì´ í–‰ë ¬ ë‚´ìš© í™•ì¸
    print("\n   Transition matrix:")
    for i in range(num_states):
        row_str = "   " + " ".join([f"{P[i,j]:.3f}" for j in range(num_states)])
        print(row_str)

    # Step 2: HMM ëª¨ë¸ ìƒì„±
    print("\n2. Creating HMM model...")
    hmm = HMMPyTorch(P)
    print(f"   Number of states: {hmm.K}")
    print(f"   Device: {hmm.device}")

    # Step 3: ê´€ì¸¡ ë°ì´í„° ì¤€ë¹„
    print("\n3. Preparing observation data...")
    batch_size, seq_len = 2, 20
    observations = torch.softmax(torch.randn(batch_size, seq_len, num_states), dim=-1)
    print(f"   Observation shape: {observations.shape}")
    print(f"   Data type: Probabilistic observations (sum to 1)")

    # Step 4: Forward-backward ì•Œê³ ë¦¬ì¦˜
    print("\n4. Running forward-backward algorithm...")
    start_time = time.time()
    posteriors, forward, backward = hmm.forward_backward(observations)
    fb_time = time.time() - start_time

    print(f"   Forward-backward time: {fb_time:.4f}s")
    print(f"   Posterior shape: {posteriors.shape}")
    print(f"   Posterior sum check: {posteriors.sum(dim=-1)[0, :5]}")  # Should be ~1.0

    # Step 5: Viterbi ë””ì½”ë”©
    print("\n5. Running Viterbi decoding...")
    start_time = time.time()
    states, scores = hmm.viterbi_decode(observations)
    viterbi_time = time.time() - start_time

    print(f"   Viterbi time: {viterbi_time:.4f}s")
    print(f"   Optimal states shape: {states.shape}")
    print(f"   State sequence (first 10): {states[0, :10].tolist()}")

    # Step 6: Likelihood ê³„ì‚°
    print("\n6. Computing sequence likelihood...")
    log_likelihood = hmm.compute_likelihood(observations)
    print(f"   Log-likelihood: {log_likelihood}")
    print(f"   Likelihood: {torch.exp(log_likelihood)}")

    return hmm, observations, posteriors, states


def tutorial_2_forward_backward_vs_viterbi():
    """íŠœí† ë¦¬ì–¼ 2: Forward-backward vs Viterbi ë¹„êµ"""
    print("\n" + "=" * 60)
    print("ğŸ“š Tutorial 2: Forward-backward vs Viterbi Comparison")
    print("=" * 60)

    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    num_states = 6
    P = create_left_to_right_matrix(num_states, self_loop_prob=0.8)
    hmm = HMMPyTorch(P)

    # ë” ê¸´ ì‹œí€€ìŠ¤ë¡œ í…ŒìŠ¤íŠ¸
    seq_len = 100
    observations = torch.softmax(torch.randn(1, seq_len, num_states), dim=-1)

    print(f"\nComparing algorithms on sequence length: {seq_len}")

    # Forward-backward
    print("\n1. Forward-backward algorithm:")
    start_time = time.time()
    posteriors, _, _ = hmm.forward_backward(observations)
    fb_time = time.time() - start_time

    # Soft alignment (ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ìƒíƒœ)
    soft_states = torch.argmax(posteriors, dim=-1)[0]

    print(f"   Time: {fb_time:.4f}s")
    print(f"   Output: Soft posteriors (probabilistic)")
    print(f"   Max posterior states: {soft_states[:15].tolist()}")

    # Viterbi
    print("\n2. Viterbi algorithm:")
    start_time = time.time()
    hard_states, scores = hmm.viterbi_decode(observations)
    viterbi_time = time.time() - start_time

    print(f"   Time: {viterbi_time:.4f}s")
    print(f"   Output: Hard alignment (deterministic)")
    print(f"   Optimal states: {hard_states[0, :15].tolist()}")

    # ê²°ê³¼ ë¹„êµ
    print("\n3. Comparison:")
    print(f"   Speed ratio (Viterbi/FB): {viterbi_time/fb_time:.2f}x")

    # ì •ë ¬ ì°¨ì´ ë¶„ì„
    agreement = (soft_states == hard_states[0]).float().mean()
    print(f"   State agreement: {agreement:.3f} ({agreement*100:.1f}%)")

    # ì§€ì†ì‹œê°„ ë¶„ì„
    soft_durations = compute_state_durations(soft_states)
    hard_durations = compute_state_durations(hard_states[0])

    print(f"   Avg duration (soft): {soft_durations.float().mean():.2f}")
    print(f"   Avg duration (hard): {hard_durations.float().mean():.2f}")

    # ì–¸ì œ ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í• ì§€ ê°€ì´ë“œ
    print("\n4. When to use which:")
    print("   ğŸ“Š Forward-backward:")
    print("      - Training (gradient computation)")
    print("      - Uncertainty quantification")
    print("      - Soft alignment for fusion")
    print("   ğŸ¯ Viterbi:")
    print("      - Inference (final alignment)")
    print("      - Real-time applications")
    print("      - Hard decision making")

    return soft_states, hard_states[0]


def tutorial_3_hmm_layer_integration():
    """íŠœí† ë¦¬ì–¼ 3: HMMLayerë¥¼ ì´ìš©í•œ ì‹ ê²½ë§ í†µí•©"""
    print("\n" + "=" * 60)
    print("ğŸ“š Tutorial 3: HMM Integration with Neural Networks")
    print("=" * 60)

    # ìŒì„± í•©ì„± ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
    print("\n1. Building TTS model with HMM alignment...")

    class SimpleTTSModel(nn.Module):
        def __init__(self, input_dim, num_phonemes, output_dim):
            super().__init__()

            # í…ìŠ¤íŠ¸ ì¸ì½”ë”
            self.text_encoder = nn.Sequential(
                nn.Linear(input_dim, 128),
                nn.ReLU(),
                nn.Linear(128, 256),
                nn.ReLU()
            )

            # HMM ì •ë ¬ ë ˆì´ì–´
            self.hmm_layer = HMMLayer(
                num_states=num_phonemes,
                learnable_transitions=True,
                transition_type="left_to_right",
                viterbi_inference=False  # Trainingì—ì„œëŠ” soft alignment
            )

            # ìŒí–¥ ë””ì½”ë”
            self.acoustic_decoder = nn.Sequential(
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Linear(128, output_dim)
            )

        def forward(self, text_features, return_alignment=False):
            # í…ìŠ¤íŠ¸ ì¸ì½”ë”©
            encoded = self.text_encoder(text_features)

            # HMM ì •ë ¬
            if return_alignment:
                aligned, alignment = self.hmm_layer(encoded, return_alignment=True)
                acoustic_output = self.acoustic_decoder(aligned)
                return acoustic_output, aligned, alignment
            else:
                aligned = self.hmm_layer(encoded)
                acoustic_output = self.acoustic_decoder(aligned)
                return acoustic_output, aligned

    # ëª¨ë¸ ìƒì„±
    input_dim, num_phonemes, output_dim = 50, 8, 80
    model = SimpleTTSModel(input_dim, num_phonemes, output_dim)

    print(f"   Model created:")
    print(f"   - Input dimension: {input_dim}")
    print(f"   - Number of phonemes: {num_phonemes}")
    print(f"   - Output dimension: {output_dim}")

    # 2. í›ˆë ¨ ì‹œë®¬ë ˆì´ì…˜
    print("\n2. Training simulation...")

    # ë”ë¯¸ ë°ì´í„°
    batch_size, seq_len = 4, 30
    text_features = torch.randn(batch_size, seq_len, input_dim)
    target_acoustic = torch.randn(batch_size, seq_len, output_dim)

    # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    print(f"   Training data shape: {text_features.shape}")
    print(f"   Target shape: {target_acoustic.shape}")

    # í›ˆë ¨ ë£¨í”„
    losses = []
    for epoch in range(5):
        optimizer.zero_grad()

        # Forward pass
        predicted_acoustic, alignment = model(text_features)

        # Loss ê³„ì‚°
        reconstruction_loss = nn.MSELoss()(predicted_acoustic, target_acoustic)

        # HMM regularization (ì˜µì…˜)
        transition_matrix = model.hmm_layer.get_transition_matrix()
        regularization = 0.01 * torch.sum(transition_matrix ** 2)

        total_loss = reconstruction_loss + regularization

        # Backward pass
        total_loss.backward()
        optimizer.step()

        losses.append(total_loss.item())
        print(f"   Epoch {epoch+1}: Loss = {total_loss.item():.4f}")

    # 3. ì¶”ë¡  í…ŒìŠ¤íŠ¸
    print("\n3. Inference test...")
    model.eval()

    with torch.no_grad():
        # Soft alignment (training mode)
        model.hmm_layer.viterbi_inference = False
        soft_output, soft_alignment = model(text_features[:1])

        # Hard alignment (inference mode)
        model.hmm_layer.viterbi_inference = True
        hard_output, hard_alignment, viterbi_path = model(
            text_features[:1], return_alignment=True)

    print(f"   Soft alignment shape: {soft_alignment.shape}")
    print(f"   Hard alignment shape: {viterbi_path.shape}")
    print(f"   Output difference: {torch.norm(soft_output - hard_output):.4f}")

    # 4. HMM íŒŒë¼ë¯¸í„° ë¶„ì„
    print("\n4. Learned HMM parameters:")
    learned_transitions = model.hmm_layer.get_transition_matrix()
    learned_initial = model.hmm_layer.get_initial_probabilities()

    print(f"   Transition matrix shape: {learned_transitions.shape}")
    print(f"   Initial probabilities: {learned_initial[:5]}")

    # ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ì „ì´ í‘œì‹œ
    max_transitions = torch.argmax(learned_transitions, dim=1)
    print(f"   Most likely transitions: {max_transitions.tolist()}")

    return model, losses


def tutorial_4_batch_processing():
    """íŠœí† ë¦¬ì–¼ 4: ë°°ì¹˜ ì²˜ë¦¬"""
    print("\n" + "=" * 60)
    print("ğŸ“š Tutorial 4: Efficient Batch Processing")
    print("=" * 60)

    # ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    num_states = 10
    P = create_left_to_right_matrix(num_states)
    hmm = HMMPyTorch(P)

    batch_sizes = [1, 4, 8, 16, 32]
    seq_len = 50

    print(f"\nBatch processing performance test:")
    print(f"Sequence length: {seq_len}, States: {num_states}")
    print(f"{'Batch Size':>10} {'Time (s)':>10} {'FPS':>10} {'Memory (MB)':>12}")
    print("-" * 50)

    for batch_size in batch_sizes:
        observations = torch.softmax(
            torch.randn(batch_size, seq_len, num_states), dim=-1)

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ (PyTorch)
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()

        # ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        with torch.no_grad():
            posteriors, _, _ = hmm.forward_backward(observations)
            states, _ = hmm.viterbi_decode(observations)
        process_time = time.time() - start_time

        # ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
        total_frames = batch_size * seq_len
        fps = total_frames / process_time

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        if torch.cuda.is_available():
            memory_mb = torch.cuda.max_memory_allocated() / 1024**2
        else:
            memory_mb = 0  # CPU ë©”ëª¨ë¦¬ëŠ” ì¶”ì •ì´ ì–´ë ¤ì›€

        print(f"{batch_size:>10} {process_time:>10.4f} {fps:>10.0f} {memory_mb:>10.1f}")

    # ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” íŒ
    print("\nğŸ’¡ Batch Processing Tips:")
    print("   1. Use larger batches for better GPU utilization")
    print("   2. Consider memory constraints with very long sequences")
    print("   3. Use torch.no_grad() for inference to save memory")
    print("   4. Pad sequences to same length for efficient batching")

    # ê°€ë³€ ê¸¸ì´ ì‹œí€€ìŠ¤ ì²˜ë¦¬ ì˜ˆì œ
    print("\nğŸ“ Variable length sequence handling:")

    # ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ì˜ ì‹œí€€ìŠ¤ë“¤
    sequences = [
        torch.softmax(torch.randn(20, num_states), dim=-1),
        torch.softmax(torch.randn(35, num_states), dim=-1),
        torch.softmax(torch.randn(28, num_states), dim=-1),
    ]

    print(f"   Sequence lengths: {[len(seq) for seq in sequences]}")

    # íŒ¨ë”©ìœ¼ë¡œ ë™ì¼í•œ ê¸¸ì´ë¡œ ë§Œë“¤ê¸°
    max_len = max(len(seq) for seq in sequences)
    padded_sequences = []
    masks = []

    for seq in sequences:
        pad_len = max_len - len(seq)
        if pad_len > 0:
            padding = torch.zeros(pad_len, num_states)
            padded_seq = torch.cat([seq, padding], dim=0)
        else:
            padded_seq = seq

        # ë§ˆìŠ¤í¬ ìƒì„± (ì‹¤ì œ ë°ì´í„° vs íŒ¨ë”©)
        mask = torch.cat([
            torch.ones(len(seq)),
            torch.zeros(pad_len)
        ]).bool()

        padded_sequences.append(padded_seq)
        masks.append(mask)

    # ë°°ì¹˜ë¡œ ìŠ¤íƒ
    batch_observations = torch.stack(padded_sequences)
    batch_masks = torch.stack(masks)

    print(f"   Padded batch shape: {batch_observations.shape}")
    print(f"   Mask shape: {batch_masks.shape}")

    # ë§ˆìŠ¤í‚¹ëœ ì²˜ë¦¬
    with torch.no_grad():
        posteriors, _, _ = hmm.forward_backward(batch_observations)

        # ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•˜ì—¬ íŒ¨ë”© ë¶€ë¶„ ì œê±°
        masked_posteriors = posteriors * batch_masks.unsqueeze(-1)

    print(f"   Masked posteriors shape: {masked_posteriors.shape}")
    print("   âœ“ Variable length sequences processed successfully!")


def tutorial_5_gpu_usage():
    """íŠœí† ë¦¬ì–¼ 5: GPU ì‚¬ìš©ë²•"""
    print("\n" + "=" * 60)
    print("ğŸ“š Tutorial 5: GPU Acceleration")
    print("=" * 60)

    # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    print(f"\n1. GPU Availability Check:")
    print(f"   CUDA available: {torch.cuda.is_available()}")

    if torch.cuda.is_available():
        print(f"   GPU device: {torch.cuda.get_device_name()}")
        print(f"   GPU memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB")
    else:
        print("   Using CPU for demonstration")

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"   Selected device: {device}")

    # 2. CPU vs GPU ì„±ëŠ¥ ë¹„êµ
    print(f"\n2. Performance Comparison:")

    num_states = 15
    batch_size = 8
    seq_len = 100

    # HMM ëª¨ë¸ ìƒì„±
    P = create_left_to_right_matrix(num_states)

    devices_to_test = ['cpu']
    if torch.cuda.is_available():
        devices_to_test.append('cuda')

    print(f"   Test configuration:")
    print(f"   - Batch size: {batch_size}")
    print(f"   - Sequence length: {seq_len}")
    print(f"   - Number of states: {num_states}")

    print(f"\n   {'Device':>8} {'Forward-Backward':>15} {'Viterbi':>10} {'Speedup':>10}")
    print("   " + "-" * 50)

    cpu_fb_time = None
    cpu_viterbi_time = None

    for test_device in devices_to_test:
        # ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        hmm = HMMPyTorch(P).to(test_device)
        observations = torch.softmax(
            torch.randn(batch_size, seq_len, num_states), dim=-1).to(test_device)

        # GPU warming up (GPUì˜ ê²½ìš°)
        if test_device == 'cuda':
            for _ in range(3):
                hmm.forward_backward(observations)
                hmm.viterbi_decode(observations)
            torch.cuda.synchronize()

        # Forward-backward ë²¤ì¹˜ë§ˆí¬
        start_time = time.time()
        for _ in range(10):  # ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ì—¬ í‰ê· 
            posteriors, _, _ = hmm.forward_backward(observations)
        if test_device == 'cuda':
            torch.cuda.synchronize()
        fb_time = (time.time() - start_time) / 10

        # Viterbi ë²¤ì¹˜ë§ˆí¬
        start_time = time.time()
        for _ in range(10):
            states, _ = hmm.viterbi_decode(observations)
        if test_device == 'cuda':
            torch.cuda.synchronize()
        viterbi_time = (time.time() - start_time) / 10

        # ìŠ¤í”¼ë“œì—… ê³„ì‚°
        if test_device == 'cpu':
            cpu_fb_time = fb_time
            cpu_viterbi_time = viterbi_time
            speedup_str = "1.0x"
        else:
            fb_speedup = cpu_fb_time / fb_time
            viterbi_speedup = cpu_viterbi_time / viterbi_time
            speedup_str = f"{fb_speedup:.1f}x/{viterbi_speedup:.1f}x"

        print(f"   {test_device.upper():>8} {fb_time:>13.4f}s {viterbi_time:>8.4f}s {speedup_str:>10}")

    # 3. GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
    if torch.cuda.is_available():
        print(f"\n3. GPU Memory Management:")

        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()

        # í° ë°°ì¹˜ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
        large_batch = 32
        large_seq = 200

        hmm = HMMPyTorch(P).cuda()
        large_obs = torch.softmax(
            torch.randn(large_batch, large_seq, num_states), dim=-1).cuda()

        print(f"   Processing large batch: {large_batch}x{large_seq}")

        initial_memory = torch.cuda.memory_allocated()
        posteriors, _, _ = hmm.forward_backward(large_obs)
        peak_memory = torch.cuda.max_memory_allocated()

        print(f"   Initial GPU memory: {initial_memory / 1024**2:.1f} MB")
        print(f"   Peak GPU memory: {peak_memory / 1024**2:.1f} MB")
        print(f"   Additional memory used: {(peak_memory - initial_memory) / 1024**2:.1f} MB")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del large_obs, posteriors
        torch.cuda.empty_cache()
        print("   âœ“ Memory cleaned up")

    # 4. ë””ë°”ì´ìŠ¤ ì´ë™ íŒ
    print(f"\n4. ğŸ’¡ GPU Usage Tips:")
    print("   â€¢ Move model to GPU: model.to('cuda')")
    print("   â€¢ Move data to GPU: data.to('cuda')")
    print("   â€¢ Use torch.cuda.synchronize() for accurate timing")
    print("   â€¢ Clear cache with torch.cuda.empty_cache()")
    print("   â€¢ Monitor memory with torch.cuda.memory_allocated()")
    print("   â€¢ Use larger batches to maximize GPU utilization")


def tutorial_6_real_world_application():
    """íŠœí† ë¦¬ì–¼ 6: ì‹¤ì œ ì‘ìš© ì˜ˆì œ"""
    print("\n" + "=" * 60)
    print("ğŸ“š Tutorial 6: Real-world Application Example")
    print("=" * 60)

    print("\nğŸ¯ Application: Phoneme Duration Modeling for TTS")
    print("Goal: Learn natural phoneme durations from speech data")

    # 1. ì‹œë®¬ë ˆì´ì…˜ëœ ìŒì„± ë°ì´í„°
    print("\n1. Simulated Speech Data:")

    # í•œêµ­ì–´ ìŒì†Œ ì˜ˆì œ
    korean_phonemes = ["sil", "a", "n", "n", "y", "eo", "ng", "h", "a", "s", "e", "y", "o", "sil"]
    phoneme_to_id = {p: i for i, p in enumerate(set(korean_phonemes))}
    id_to_phoneme = {i: p for p, i in phoneme_to_id.items()}

    print(f"   Text: 'ì•ˆë…•í•˜ì„¸ìš”' (Hello in Korean)")
    print(f"   Phonemes: {korean_phonemes}")
    print(f"   Vocabulary size: {len(phoneme_to_id)}")

    # ìŒì„± íŠ¹ì§• ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” MFCC, ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë“±)
    num_frames = 150  # 1.5ì´ˆ @ 100fps
    feature_dim = 40

    # ê° ìŒì†Œë§ˆë‹¤ ë‹¤ë¥¸ íŠ¹ì§• íŒ¨í„´
    speech_features = []
    true_alignment = []

    frame_idx = 0
    for phoneme in korean_phonemes:
        phoneme_id = phoneme_to_id[phoneme]

        # ìŒì†Œë³„ ì§€ì†ì‹œê°„ (ì‹¤ì œë¡œëŠ” ë°ì´í„°ì—ì„œ ì¶”ì¶œ)
        if phoneme == "sil":
            duration = np.random.randint(8, 15)  # ì¹¨ë¬µì€ ê¸¸ê²Œ
        elif phoneme in ["a", "e", "o", "y"]:
            duration = np.random.randint(12, 20)  # ëª¨ìŒì€ ê¸¸ê²Œ
        else:
            duration = np.random.randint(6, 12)   # ììŒì€ ì§§ê²Œ

        # ìŒì†Œë³„ íŠ¹ì§• ìƒì„± (ê° ìŒì†Œë§ˆë‹¤ ê³ ìœ í•œ íŒ¨í„´)
        base_feature = torch.randn(feature_dim) * 0.5
        for _ in range(duration):
            if frame_idx < num_frames:
                noise = torch.randn(feature_dim) * 0.1
                frame_feature = base_feature + noise
                speech_features.append(frame_feature)
                true_alignment.append(phoneme_id)
                frame_idx += 1

    # ë¶€ì¡±í•œ í”„ë ˆì„ ì±„ìš°ê¸°
    while len(speech_features) < num_frames:
        speech_features.append(torch.zeros(feature_dim))
        true_alignment.append(phoneme_to_id["sil"])

    speech_features = torch.stack(speech_features[:num_frames])
    true_alignment = torch.tensor(true_alignment[:num_frames])

    print(f"   Speech features shape: {speech_features.shape}")
    print(f"   True alignment length: {len(true_alignment)}")

    # 2. HMM ê¸°ë°˜ ì •ë ¬ ëª¨ë¸
    print("\n2. HMM Alignment Model:")

    num_phonemes = len(phoneme_to_id)

    # Gaussian HMMìœ¼ë¡œ ìŒì†Œ ëª¨ë¸ë§
    hmm_model = GaussianHMMLayer(
        num_states=num_phonemes,
        feature_dim=feature_dim,
        covariance_type='diag',
        learnable_transitions=True,
        transition_type="left_to_right"
    )

    print(f"   Model type: Gaussian HMM")
    print(f"   Number of phonemes: {num_phonemes}")
    print(f"   Feature dimension: {feature_dim}")

    # 3. ëª¨ë¸ í›ˆë ¨
    print("\n3. Training Alignment Model:")

    optimizer = optim.Adam(hmm_model.parameters(), lr=0.01)

    # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
    batch_speech = speech_features.unsqueeze(0)  # (1, T, D)

    training_losses = []

    for epoch in range(50):  # ë¹ ë¥¸ ë°ëª¨ë¥¼ ìœ„í•´ 50 ì—í¬í¬
        optimizer.zero_grad()

        # Forward pass
        posteriors = hmm_model(batch_speech)

        # ì§€ë„í•™ìŠµ: ì‹¤ì œ ì •ë ¬ê³¼ì˜ cross-entropy loss
        loss = nn.CrossEntropyLoss()(
            posteriors.view(-1, num_phonemes),
            true_alignment
        )

        # Backward pass
        loss.backward()
        optimizer.step()

        training_losses.append(loss.item())

        if (epoch + 1) % 10 == 0:
            print(f"   Epoch {epoch+1:2d}: Loss = {loss.item():.4f}")

    # 4. ì •ë ¬ ê²°ê³¼ í‰ê°€
    print("\n4. Alignment Evaluation:")

    with torch.no_grad():
        hmm_model.eval()

        # HMM ì •ë ¬ ìˆ˜í–‰
        predicted_posteriors = hmm_model(batch_speech)
        predicted_alignment = torch.argmax(predicted_posteriors, dim=-1)[0]

        # ì •í™•ë„ ê³„ì‚°
        accuracy = (predicted_alignment == true_alignment).float().mean()
        print(f"   Alignment accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)")

        # ìŒì†Œë³„ ì§€ì†ì‹œê°„ ë¶„ì„
        true_durations = compute_state_durations(true_alignment)
        pred_durations = compute_state_durations(predicted_alignment)

        print(f"\n   Duration comparison:")
        print(f"   {'Phoneme':>8} {'True':>6} {'Pred':>6} {'Error':>7}")
        print("   " + "-" * 30)

        for phoneme_id in range(min(8, num_phonemes)):  # ì²˜ìŒ 8ê°œë§Œ í‘œì‹œ
            phoneme = id_to_phoneme[phoneme_id]
            true_dur = true_durations[phoneme_id].item() if phoneme_id < len(true_durations) else 0
            pred_dur = pred_durations[phoneme_id].item() if phoneme_id < len(pred_durations) else 0
            error = abs(true_dur - pred_dur)

            print(f"   {phoneme:>8} {true_dur:>6} {pred_dur:>6} {error:>7}")

    # 5. ê²°ê³¼ ì‹œê°í™” (í…ìŠ¤íŠ¸ ê¸°ë°˜)
    print("\n5. Alignment Visualization:")

    # ì²˜ìŒ 50 í”„ë ˆì„ì˜ ì •ë ¬ ë¹„êµ
    print("   Frame-by-frame alignment (first 50 frames):")
    print("   Frame:  ", end="")
    for i in range(0, 50, 5):
        print(f"{i:>3}", end="")
    print()

    print("   True:   ", end="")
    for i in range(0, 50, 5):
        phoneme = id_to_phoneme[true_alignment[i].item()][:2]
        print(f"{phoneme:>3}", end="")
    print()

    print("   Pred:   ", end="")
    for i in range(0, 50, 5):
        phoneme = id_to_phoneme[predicted_alignment[i].item()][:2]
        print(f"{phoneme:>3}", end="")
    print()

    # 6. ì‹¤ì œ ì‘ìš© ê°€ì´ë“œ
    print("\n6. ğŸ’¡ Real-world Application Guide:")
    print("   ğŸ“Š Data Preparation:")
    print("      - Extract MFCC/mel-spectrogram from audio")
    print("      - Obtain phoneme transcriptions")
    print("      - Align text and audio (forced alignment)")

    print("   ğŸ¯ Model Training:")
    print("      - Use larger datasets (hours of speech)")
    print("      - Add speaker adaptation")
    print("      - Include prosodic features")

    print("   ğŸš€ Deployment:")
    print("      - Optimize for real-time inference")
    print("      - Use quantization for mobile devices")
    print("      - Cache frequently used models")

    return hmm_model, accuracy, training_losses


def main():
    """ëª¨ë“  íŠœí† ë¦¬ì–¼ ì‹¤í–‰"""
    print("ğŸ“ PyTorch HMM Basic Tutorial")
    print("=" * 70)

    # ì‹œë“œ ì„¤ì •
    torch.manual_seed(42)
    np.random.seed(42)

    print("Welcome to PyTorch HMM Basic Tutorial!")
    print("This tutorial covers essential concepts and practical usage.")

    try:
        # íŠœí† ë¦¬ì–¼ 1: ê¸°ë³¸ ì‚¬ìš©ë²•
        hmm, observations, posteriors, states = tutorial_1_basic_hmm()

        # íŠœí† ë¦¬ì–¼ 2: ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
        soft_states, hard_states = tutorial_2_forward_backward_vs_viterbi()

        # íŠœí† ë¦¬ì–¼ 3: ì‹ ê²½ë§ í†µí•©
        model, losses = tutorial_3_hmm_layer_integration()

        # íŠœí† ë¦¬ì–¼ 4: ë°°ì¹˜ ì²˜ë¦¬
        tutorial_4_batch_processing()

        # íŠœí† ë¦¬ì–¼ 5: GPU ì‚¬ìš©ë²•
        tutorial_5_gpu_usage()

        # íŠœí† ë¦¬ì–¼ 6: ì‹¤ì œ ì‘ìš©
        tts_model, accuracy, training_losses = tutorial_6_real_world_application()

        # ìµœì¢… ìš”ì•½
        print("\n" + "=" * 70)
        print("ğŸ‰ Tutorial Completed Successfully!")
        print("=" * 70)

        print("\nWhat you've learned:")
        print("âœ“ Basic HMM operations (forward-backward, Viterbi)")
        print("âœ“ Algorithm trade-offs and when to use each")
        print("âœ“ Integration with PyTorch neural networks")
        print("âœ“ Efficient batch processing techniques")
        print("âœ“ GPU acceleration and optimization")
        print("âœ“ Real-world application development")

        print(f"\nKey Results:")
        print(f"â€¢ Final TTS model alignment accuracy: {accuracy:.1%}")
        print(f"â€¢ Learned transition parameters successfully")
        print(f"â€¢ Demonstrated {len(losses)} epochs of training")

        print(f"\nNext Steps:")
        print("ğŸ“š Explore advanced_features_demo.py for cutting-edge features")
        print("ğŸ”¬ Try the integration tests: python tests/test_integration.py")
        print("ğŸš€ Build your own speech synthesis application!")

    except Exception as e:
        print(f"\nâŒ Tutorial failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
