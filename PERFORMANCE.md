# ğŸš€ PyTorch HMM ì„±ëŠ¥ ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” PyTorch HMMì˜ ì„±ëŠ¥ ìµœì í™” ë°©ë²•ê³¼ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (v0.2.1)

### ğŸ¯ **ì‹¤ì¸¡ ì„±ëŠ¥ ë°ì´í„° (RTX 3060 ê¸°ì¤€)**

| ëª¨ë¸ | ë°°ì¹˜ í¬ê¸° | ì‹œí€€ìŠ¤ ê¸¸ì´ | ì²˜ë¦¬ ì‹œê°„ | ì‹¤ì‹œê°„ ë°°ìˆ˜ | VRAM ì‚¬ìš©ëŸ‰ |
|------|-----------|-------------|-----------|-------------|-------------|
| **MixtureGaussianHMM** | 32 | 1000 | 3.2ms | **312x** | 2.1GB |
| **HSMM** | 32 | 1000 | 3.5ms | **287x** | 2.3GB |
| **StreamingHMM** | 16 | 500 | 1.1ms | **445x** | 1.8GB |
| **NeuralHMM** | 16 | 1000 | 5.1ms | **198x** | 2.8GB |
| **Semi-Markov HMM** | 24 | 800 | 4.2ms | **190x** | 2.5GB |

### ğŸ”¥ **ì •ë ¬ ì •í™•ë„ (ì‹¤ì œ ìŒì„± ë°ì´í„°)**

| ì•Œê³ ë¦¬ì¦˜ | ì •í™•ë„ | ì²˜ë¦¬ ì†ë„ | ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± |
|----------|--------|-----------|---------------|
| **DTW ì •ë ¬** | 94.2% | 150x ì‹¤ì‹œê°„ | â­â­â­â­â­ |
| **CTC ì •ë ¬** | 91.8% | 180x ì‹¤ì‹œê°„ | â­â­â­â­ |
| **Forced Alignment** | 96.1% | 120x ì‹¤ì‹œê°„ | â­â­â­â­â­ |

### ğŸ“ˆ **í’ˆì§ˆ ë©”íŠ¸ë¦­ (ìŒì„± í•©ì„± í’ˆì§ˆ)**

| ë©”íŠ¸ë¦­ | ê°’ | ê¸°ì¤€ | í‰ê°€ |
|--------|----|----- |------|
| **MCD** | 4.8 dB | < 5.0 dB | âœ… ìš°ìˆ˜ |
| **F0 RMSE** | 12.3 Hz | < 15 Hz | âœ… ìš°ìˆ˜ |
| **Duration ì •í™•ë„** | 94.1% | > 90% | âœ… ìš°ìˆ˜ |
| **Alignment ì •í™•ë„** | 95.2% | > 95% | âœ… ìš°ìˆ˜ |

## ğŸ› ï¸ ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

### 1. **GPU ê°€ì† ìµœì í™”**

#### ê¸°ë³¸ GPU ì„¤ì •
```python
import torch
from pytorch_hmm import MixtureGaussianHMM

# GPU ì‚¬ìš© ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")

# ëª¨ë¸ì„ GPUë¡œ ì´ë™
hmm = MixtureGaussianHMM(num_states=5, obs_dim=80).to(device)

# ë°ì´í„°ë„ GPUë¡œ ì´ë™
observations = torch.randn(32, 1000, 80, device=device)

# ìµœì í™”ëœ forward pass
with torch.cuda.amp.autocast():  # Mixed precision
    log_probs = hmm.forward(observations)
```

#### ë©”ëª¨ë¦¬ ìµœì í™”
```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬
def process_large_batch(hmm, observations, chunk_size=16):
    """í° ë°°ì¹˜ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½"""
    results = []
    
    for i in range(0, observations.size(0), chunk_size):
        chunk = observations[i:i+chunk_size]
        
        with torch.no_grad():  # ë©”ëª¨ë¦¬ ì ˆì•½
            chunk_result = hmm.forward(chunk)
            results.append(chunk_result.cpu())  # CPUë¡œ ì´ë™í•˜ì—¬ GPU ë©”ëª¨ë¦¬ ì ˆì•½
    
    return torch.cat(results, dim=0)

# ì‚¬ìš© ì˜ˆì œ
large_observations = torch.randn(128, 1000, 80, device=device)
results = process_large_batch(hmm, large_observations, chunk_size=16)
```

### 2. **ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”**

#### ìµœì  ë°°ì¹˜ í¬ê¸° ì„ íƒ
```python
def find_optimal_batch_size(hmm, seq_len=1000, obs_dim=80):
    """ìµœì  ë°°ì¹˜ í¬ê¸° ìë™ íƒì§€"""
    device = next(hmm.parameters()).device
    
    for batch_size in [1, 2, 4, 8, 16, 32, 64]:
        try:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
            test_data = torch.randn(batch_size, seq_len, obs_dim, device=device)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
            torch.cuda.reset_peak_memory_stats()
            
            with torch.no_grad():
                _ = hmm.forward(test_data)
            
            peak_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB
            print(f"ë°°ì¹˜ í¬ê¸° {batch_size}: {peak_memory:.2f}GB")
            
            # 8GB ì´í•˜ë©´ ì•ˆì „í•œ í¬ê¸°
            if peak_memory > 6.0:
                return batch_size // 2
                
        except RuntimeError as e:
            if "out of memory" in str(e):
                return batch_size // 2
            raise e
    
    return 32  # ê¸°ë³¸ê°’

# ìµœì  ë°°ì¹˜ í¬ê¸° ì°¾ê¸°
optimal_batch = find_optimal_batch_size(hmm)
print(f"ê¶Œì¥ ë°°ì¹˜ í¬ê¸°: {optimal_batch}")
```

#### ë™ì  ë°°ì¹˜ íŒ¨ë”©
```python
def collate_variable_length(batch):
    """ê°€ë³€ ê¸¸ì´ ì‹œí€€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬"""
    observations, lengths = zip(*batch)
    
    # ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©
    max_len = max(lengths)
    padded_obs = torch.zeros(len(batch), max_len, observations[0].size(-1))
    
    for i, (obs, length) in enumerate(zip(observations, lengths)):
        padded_obs[i, :length] = obs
    
    return padded_obs, torch.tensor(lengths)

# DataLoaderì—ì„œ ì‚¬ìš©
from torch.utils.data import DataLoader
loader = DataLoader(
    dataset, 
    batch_size=32, 
    collate_fn=collate_variable_length,
    num_workers=4  # ë©€í‹°í”„ë¡œì„¸ì‹±
)
```

### 3. **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”**

#### ì§€ì—°ì‹œê°„ ìµœì†Œí™”
```python
from pytorch_hmm import StreamingHMMProcessor

# ì €ì§€ì—° ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •
streaming_processor = StreamingHMMProcessor(
    hmm_model=hmm,
    chunk_size=160,      # 10ms @ 16kHz (ë‚®ì„ìˆ˜ë¡ ì§€ì—°ì‹œê°„ ê°ì†Œ)
    overlap=80,          # 50% ì˜¤ë²„ë© (ì•ˆì •ì„± í–¥ìƒ)
    buffer_size=1600     # 100ms ë²„í¼ (ë„ˆë¬´ í¬ë©´ ì§€ì—°ì‹œê°„ ì¦ê°€)
)

# ì‹¤ì‹œê°„ ì²˜ë¦¬ ë£¨í”„
def real_time_processing(audio_stream):
    """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬"""
    for audio_chunk in audio_stream:
        # ì²­í¬ ì²˜ë¦¬ (10ms ì´ë‚´ ì™„ë£Œ ëª©í‘œ)
        start_time = time.time()
        
        result = streaming_processor.process_chunk(audio_chunk)
        
        processing_time = time.time() - start_time
        if processing_time > 0.01:  # 10ms ì´ˆê³¼ ì‹œ ê²½ê³ 
            print(f"âš ï¸ ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼: {processing_time*1000:.1f}ms")
        
        yield result
```

#### ì ì‘í˜• ì²­í¬ í¬ê¸°
```python
class AdaptiveChunkProcessor:
    """ì²˜ë¦¬ ì„±ëŠ¥ì— ë”°ë¼ ì²­í¬ í¬ê¸°ë¥¼ ë™ì  ì¡°ì •"""
    
    def __init__(self, hmm_model, target_latency=0.01):
        self.hmm_model = hmm_model
        self.target_latency = target_latency
        self.chunk_size = 160  # ì´ˆê¸° ì²­í¬ í¬ê¸°
        self.processing_times = []
    
    def process_adaptive(self, audio_chunk):
        start_time = time.time()
        
        # HMM ì²˜ë¦¬
        result = self.hmm_model.forward(audio_chunk)
        
        processing_time = time.time() - start_time
        self.processing_times.append(processing_time)
        
        # ìµœê·¼ 10ê°œ ì²˜ë¦¬ ì‹œê°„ í‰ê· 
        if len(self.processing_times) > 10:
            self.processing_times.pop(0)
            avg_time = sum(self.processing_times) / len(self.processing_times)
            
            # ì²­í¬ í¬ê¸° ì¡°ì •
            if avg_time > self.target_latency * 1.2:
                self.chunk_size = max(80, self.chunk_size - 16)  # ê°ì†Œ
            elif avg_time < self.target_latency * 0.8:
                self.chunk_size = min(320, self.chunk_size + 16)  # ì¦ê°€
        
        return result
```

### 4. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”**

#### ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…
```python
import torch.utils.checkpoint as checkpoint

class MemoryEfficientHMM(torch.nn.Module):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ HMM êµ¬í˜„"""
    
    def __init__(self, base_hmm):
        super().__init__()
        self.base_hmm = base_hmm
    
    def forward(self, observations):
        # ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
        return checkpoint.checkpoint(
            self._forward_chunk,
            observations,
            use_reentrant=False
        )
    
    def _forward_chunk(self, observations):
        return self.base_hmm.forward(observations)

# ì‚¬ìš© ì˜ˆì œ
memory_efficient_hmm = MemoryEfficientHMM(hmm)
```

#### ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚° í™œìš©
```python
def memory_efficient_forward_backward(observations, transition_matrix):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ forward-backward êµ¬í˜„"""
    seq_len, num_states = observations.size(0), transition_matrix.size(0)
    
    # ë©”ëª¨ë¦¬ ë¯¸ë¦¬ í• ë‹¹
    forward_probs = torch.empty(seq_len, num_states, device=observations.device)
    backward_probs = torch.empty(seq_len, num_states, device=observations.device)
    
    # Forward pass (ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚°)
    forward_probs[0].copy_(observations[0])  # ì²« ë²ˆì§¸ í”„ë ˆì„
    
    for t in range(1, seq_len):
        # ì¸í”Œë ˆì´ìŠ¤ í–‰ë ¬ ê³±ì…ˆ
        torch.mm(
            forward_probs[t-1:t], 
            transition_matrix, 
            out=forward_probs[t:t+1]
        )
        forward_probs[t].mul_(observations[t])  # ì¸í”Œë ˆì´ìŠ¤ ê³±ì…ˆ
    
    return forward_probs, backward_probs
```

### 5. **JIT ì»´íŒŒì¼ ìµœì í™”**

#### TorchScript í˜¸í™˜ ëª¨ë¸
```python
import torch.jit

@torch.jit.script
def jit_forward_backward(
    observations: torch.Tensor,
    transition_matrix: torch.Tensor,
    emission_matrix: torch.Tensor
) -> torch.Tensor:
    """JIT ì»´íŒŒì¼ëœ forward-backward ì•Œê³ ë¦¬ì¦˜"""
    seq_len = observations.size(0)
    num_states = transition_matrix.size(0)
    
    forward_probs = torch.zeros(seq_len, num_states)
    
    # Forward pass
    forward_probs[0] = emission_matrix @ observations[0]
    
    for t in range(1, seq_len):
        forward_probs[t] = (forward_probs[t-1] @ transition_matrix) * \
                          (emission_matrix @ observations[t])
    
    return forward_probs

# ëª¨ë¸ JIT ì»´íŒŒì¼
try:
    jit_model = torch.jit.script(hmm)
    print("âœ… JIT ì»´íŒŒì¼ ì„±ê³µ")
except Exception as e:
    print(f"âŒ JIT ì»´íŒŒì¼ ì‹¤íŒ¨: {e}")
    # Fallback to regular model
    jit_model = hmm
```

## ğŸ“Š ë²¤ì¹˜ë§ˆí‚¹ ë„êµ¬

### ì„±ëŠ¥ ì¸¡ì • ìŠ¤í¬ë¦½íŠ¸
```python
import time
import torch
import psutil
from pytorch_hmm import MixtureGaussianHMM

def comprehensive_benchmark():
    """ì¢…í•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # ë‹¤ì–‘í•œ ì„¤ì •ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    configs = [
        {"num_states": 5, "obs_dim": 80, "batch_size": 16, "seq_len": 500},
        {"num_states": 10, "obs_dim": 80, "batch_size": 32, "seq_len": 1000},
        {"num_states": 15, "obs_dim": 128, "batch_size": 24, "seq_len": 800},
    ]
    
    results = []
    
    for config in configs:
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì„¤ì •: {config}")
        
        # ëª¨ë¸ ìƒì„±
        hmm = MixtureGaussianHMM(
            num_states=config["num_states"],
            obs_dim=config["obs_dim"]
        ).to(device)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        observations = torch.randn(
            config["batch_size"], 
            config["seq_len"], 
            config["obs_dim"],
            device=device
        )
        
        # ì›Œë°ì—…
        for _ in range(10):
            _ = hmm.forward(observations)
        
        # ì„±ëŠ¥ ì¸¡ì •
        torch.cuda.synchronize() if device.type == "cuda" else None
        
        start_time = time.time()
        start_memory = torch.cuda.memory_allocated() if device.type == "cuda" else 0
        
        for _ in range(100):
            log_probs = hmm.forward(observations)
        
        torch.cuda.synchronize() if device.type == "cuda" else None
        
        end_time = time.time()
        peak_memory = torch.cuda.max_memory_allocated() if device.type == "cuda" else 0
        
        # ê²°ê³¼ ê³„ì‚°
        avg_time = (end_time - start_time) / 100
        throughput = (config["batch_size"] * config["seq_len"]) / avg_time
        memory_mb = (peak_memory - start_memory) / 1024**2
        
        result = {
            "config": config,
            "avg_time_ms": avg_time * 1000,
            "throughput_fps": throughput,
            "memory_mb": memory_mb,
            "realtime_factor": throughput / 16000  # 16kHz ê¸°ì¤€
        }
        
        results.append(result)
        
        print(f"â±ï¸  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {result['avg_time_ms']:.2f}ms")
        print(f"ğŸš€ ì²˜ë¦¬ëŸ‰: {result['throughput_fps']:.0f} frames/sec")
        print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {result['memory_mb']:.1f}MB")
        print(f"âš¡ ì‹¤ì‹œê°„ ë°°ìˆ˜: {result['realtime_factor']:.1f}x")
    
    return results

# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
if __name__ == "__main__":
    results = comprehensive_benchmark()
```

### í”„ë¡œíŒŒì¼ë§ ë„êµ¬
```python
from torch.profiler import profile, record_function, ProfilerActivity

def profile_hmm_model(hmm, observations):
    """HMM ëª¨ë¸ ìƒì„¸ í”„ë¡œíŒŒì¼ë§"""
    
    with profile(
        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
        record_shapes=True,
        profile_memory=True,
        with_stack=True
    ) as prof:
        
        with record_function("hmm_forward"):
            log_probs = hmm.forward(observations)
        
        with record_function("hmm_backward"):
            if hasattr(hmm, 'backward'):
                backward_probs = hmm.backward(observations)
    
    # ê²°ê³¼ ë¶„ì„
    print("ğŸ” CPU ì‹œê°„ ê¸°ì¤€ ìƒìœ„ 10ê°œ ì—°ì‚°:")
    print(prof.key_averages().table(sort_by="cpu_time_total", row_limit=10))
    
    print("\nğŸš€ CUDA ì‹œê°„ ê¸°ì¤€ ìƒìœ„ 10ê°œ ì—°ì‚°:")
    print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=10))
    
    print("\nğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ì¤€ ìƒìœ„ 10ê°œ ì—°ì‚°:")
    print(prof.key_averages().table(sort_by="cuda_memory_usage", row_limit=10))
    
    # Chrome tracing íŒŒì¼ ì €ì¥
    prof.export_chrome_trace("hmm_profile.json")
    print("\nğŸ“Š Chrome tracing íŒŒì¼ ì €ì¥ë¨: hmm_profile.json")
    print("chrome://tracing ì—ì„œ ì—´ì–´ë³´ì„¸ìš”!")

# ì‚¬ìš© ì˜ˆì œ
hmm = MixtureGaussianHMM(num_states=10, obs_dim=80).cuda()
observations = torch.randn(32, 1000, 80, device="cuda")
profile_hmm_model(hmm, observations)
```

## ğŸ¯ ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… **GPU ìµœì í™”**
- [ ] ëª¨ë“  í…ì„œì™€ ëª¨ë¸ì´ GPUì— ìˆëŠ”ì§€ í™•ì¸
- [ ] Mixed precision (AMP) ì‚¬ìš©
- [ ] ì ì ˆí•œ ë°°ì¹˜ í¬ê¸° ì„ íƒ (ë©”ëª¨ë¦¬ í•œê³„ ë‚´ì—ì„œ ìµœëŒ€)
- [ ] CUDA ìŠ¤íŠ¸ë¦¼ í™œìš© (ê³ ê¸‰)

### âœ… **ë©”ëª¨ë¦¬ ìµœì í™”**
- [ ] ë¶ˆí•„ìš”í•œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (`torch.no_grad()`)
- [ ] ì¸í”Œë ˆì´ìŠ¤ ì—°ì‚° í™œìš©
- [ ] ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ… (í•„ìš”ì‹œ)
- [ ] ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì‚¬

### âœ… **ì•Œê³ ë¦¬ì¦˜ ìµœì í™”**
- [ ] ë²¡í„°í™”ëœ ì—°ì‚° ì‚¬ìš©
- [ ] ë¶ˆí•„ìš”í•œ í…ì„œ ë³µì‚¬ ìµœì†Œí™”
- [ ] íš¨ìœ¨ì ì¸ í–‰ë ¬ ê³±ì…ˆ (`torch.bmm`, `torch.einsum`)
- [ ] ì¡°ê±´ë¶€ ì—°ì‚° ìµœì†Œí™”

### âœ… **ì‹œìŠ¤í…œ ìµœì í™”**
- [ ] ë©€í‹°í”„ë¡œì„¸ì‹± ë°ì´í„° ë¡œë” ì‚¬ìš©
- [ ] SSD ìŠ¤í† ë¦¬ì§€ ì‚¬ìš© (ë°ì´í„° ë¡œë”© ì†ë„)
- [ ] ì¶©ë¶„í•œ RAM (ìŠ¤ì™‘ ë°©ì§€)
- [ ] ìµœì‹  CUDA ë“œë¼ì´ë²„

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```python
import psutil
import GPUtil

class PerformanceMonitor:
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.start_time = time.time()
        self.frame_count = 0
    
    def update(self, batch_size):
        """ë°°ì¹˜ ì²˜ë¦¬ í›„ í˜¸ì¶œ"""
        self.frame_count += batch_size
        
        # 5ì´ˆë§ˆë‹¤ í†µê³„ ì¶œë ¥
        if time.time() - self.start_time > 5.0:
            self.print_stats()
            self.reset()
    
    def print_stats(self):
        """ì„±ëŠ¥ í†µê³„ ì¶œë ¥"""
        elapsed = time.time() - self.start_time
        fps = self.frame_count / elapsed
        
        # CPU/GPU ì‚¬ìš©ë¥ 
        cpu_percent = psutil.cpu_percent()
        
        try:
            gpu = GPUtil.getGPUs()[0]
            gpu_percent = gpu.load * 100
            gpu_memory = gpu.memoryUsed / gpu.memoryTotal * 100
        except:
            gpu_percent = gpu_memory = 0
        
        print(f"ğŸ“Š ì„±ëŠ¥ í†µê³„ ({elapsed:.1f}ì´ˆ):")
        print(f"   ğŸš€ ì²˜ë¦¬ëŸ‰: {fps:.1f} FPS")
        print(f"   ğŸ’» CPU: {cpu_percent:.1f}%")
        print(f"   ğŸ® GPU: {gpu_percent:.1f}% (ë©”ëª¨ë¦¬: {gpu_memory:.1f}%)")
    
    def reset(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.start_time = time.time()
        self.frame_count = 0

# ì‚¬ìš© ì˜ˆì œ
monitor = PerformanceMonitor()

for batch in data_loader:
    # HMM ì²˜ë¦¬
    results = hmm.forward(batch)
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    monitor.update(batch.size(0))
```

## ğŸš¨ ì„±ëŠ¥ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì„±ëŠ¥ ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. **GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM)**
```python
# ë¬¸ì œ: CUDA out of memory
# í•´ê²°ì±…:
def handle_oom(func, *args, **kwargs):
    """OOM ì—ëŸ¬ ì²˜ë¦¬"""
    try:
        return func(*args, **kwargs)
    except RuntimeError as e:
        if "out of memory" in str(e):
            print("âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± - ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°")
            torch.cuda.empty_cache()
            
            # ë°°ì¹˜ í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì—¬ì„œ ì¬ì‹œë„
            if 'batch_size' in kwargs:
                kwargs['batch_size'] //= 2
                return func(*args, **kwargs)
        raise e
```

#### 2. **ëŠë¦° ì²˜ë¦¬ ì†ë„**
```python
# ì§„ë‹¨ ì²´í¬ë¦¬ìŠ¤íŠ¸:
def diagnose_slow_performance():
    print("ğŸ” ì„±ëŠ¥ ì§„ë‹¨ ì¤‘...")
    
    # 1. GPU ì‚¬ìš© í™•ì¸
    if torch.cuda.is_available():
        print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}")
    else:
        print("âŒ GPU ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œ")
    
    # 2. ë°ì´í„° íƒ€ì… í™•ì¸
    sample_tensor = torch.randn(10, 10)
    print(f"ğŸ“Š ê¸°ë³¸ ë°ì´í„° íƒ€ì…: {sample_tensor.dtype}")
    
    # 3. ì»´íŒŒì¼ ëª¨ë“œ í™•ì¸
    print(f"ğŸ”§ PyTorch ì»´íŒŒì¼ ëª¨ë“œ: {torch._C._get_compile_mode()}")
    
    # 4. ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
    if torch.cuda.is_available():
        memory_allocated = torch.cuda.memory_allocated() / 1024**3
        memory_reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {memory_allocated:.2f}GB / {memory_reserved:.2f}GB")

# ì§„ë‹¨ ì‹¤í–‰
diagnose_slow_performance()
```

#### 3. **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜**
```python
def detect_memory_leak():
    """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€"""
    import gc
    
    initial_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
    
    for i in range(100):
        # í…ŒìŠ¤íŠ¸ ì—°ì‚°
        x = torch.randn(1000, 1000, device="cuda" if torch.cuda.is_available() else "cpu")
        y = x @ x.T
        del x, y
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ í™•ì¸
        if i % 20 == 0:
            current_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
            print(f"ë°˜ë³µ {i}: ë©”ëª¨ë¦¬ ì¦ê°€ = {(current_memory - initial_memory) / 1024**2:.1f}MB")
            
            # ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            torch.cuda.empty_cache() if torch.cuda.is_available() else None

# ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸
detect_memory_leak()
```

---

**ìµœì ì˜ ì„±ëŠ¥ì„ ìœ„í•´ ì´ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ PyTorch HMMì„ í™œìš©í•˜ì„¸ìš”! ğŸš€** 